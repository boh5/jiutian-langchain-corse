{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da753e4-a17e-4d79-89f1-2ccee935b4e4",
   "metadata": {},
   "source": [
    "## <font face=\"ä»¿å®‹\">è¯¾ç¨‹è¯´æ˜ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316716c-9254-484c-b19c-061fddb6e502",
   "metadata": {},
   "source": [
    "- ä½“éªŒè¯¾å†…å®¹èŠ‚é€‰è‡ª[ã€Š2025å¤§æ¨¡å‹Agentæ™ºèƒ½ä½“å¼€å‘å®æˆ˜ã€‹(å¤å­£ç­)](https://ix9mq.xetslk.com/s/2lPSMo)å®Œæ•´ç‰ˆä»˜è´¹è¯¾ç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f6b3b-4bdb-4cf9-80f4-4b0950d56eb8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä½“éªŒè¯¾æ—¶é—´æœ‰é™ï¼Œè‹¥æƒ³æ·±åº¦å­¦ä¹ å¤§æ¨¡å‹æŠ€æœ¯ï¼Œæ¬¢è¿å¤§å®¶æŠ¥åç”±æˆ‘ä¸»è®²çš„[ã€Š2025å¤§æ¨¡å‹Agentæ™ºèƒ½ä½“å¼€å‘å®æˆ˜ã€‹(å¤å­£ç­)](https://ix9mq.xetslk.com/s/2lPSMo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b3522-d8b3-4246-8be6-8ef0464eaa40",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171642034.jpg\" alt=\"bef0897853f861af5f4211442be446b\" style=\"zoom:15%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de4c0f-25cc-43ca-a946-c1dd4e62386b",
   "metadata": {},
   "source": [
    "**[ã€Š2025å¤§æ¨¡å‹Agentæ™ºèƒ½ä½“å¼€å‘å®æˆ˜ã€‹(å¤å­£ç­)](https://ix9mq.xetslk.com/s/2lPSMo)ä¸ºã€100+å°æ—¶ã€‘ä½“ç³»å¤§è¯¾ï¼Œæ€»å…±20å¤§æ¨¡å—ç²¾è®²ç²¾æï¼Œé›¶åŸºç¡€ç›´è¾¾å¤§æ¨¡å‹ä¼ä¸šçº§åº”ç”¨ï¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78151d8d-a1b8-4409-a321-d742e80e273c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506172010074.png\" alt=\"a55d48e952ed59f8d93e050594843bc\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b720c-bcad-4ed4-a26b-00567f46645d",
   "metadata": {},
   "source": [
    "éƒ¨åˆ†é¡¹ç›®æˆæœæ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236f0661-2453-4a35-9749-b8e1d3680ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d1aca-f86a-4912-a197-b608b066f596",
   "metadata": {},
   "source": [
    "- **MateGené¡¹ç›®æ¼”ç¤º**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce8298a-875e-4acb-84a4-347a989e36e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/MG%E6%BC%94%E7%A4%BA%E8%A7%86%E9%A2%91.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/MG%E6%BC%94%E7%A4%BA%E8%A7%86%E9%A2%91.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21220db2-bf1c-4669-90e9-46be9510cdd4",
   "metadata": {},
   "source": [
    "- **æ™ºèƒ½å®¢æœé¡¹ç›®æ¼”ç¤º**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3dce8f-d1ec-4fad-930d-5d0b08a31986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E6%A1%88%E4%BE%8B%E8%A7%86%E9%A2%91.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E6%A1%88%E4%BE%8B%E8%A7%86%E9%A2%91.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0f7bb-2893-471a-81f8-508e0ce3f10a",
   "metadata": {},
   "source": [
    "- **Difyé¡¹ç›®æ¼”ç¤º**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315526bc-9ad2-4772-9184-eea4a2897a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/2f1b47f42c65fd59e8d3a83e6cb9f13b_raw.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/2f1b47f42c65fd59e8d3a83e6cb9f13b_raw.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aace7fd-3119-4c7b-9d33-fa3c118c8205",
   "metadata": {},
   "source": [
    "- **LangChain&LangGraphæ­å»ºMulti-Agnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab0e566-79ce-4714-87a4-0cf7ebad6524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90Multi-Agent%E6%95%88%E6%9E%9C%E6%BC%94%E7%A4%BA%E6%95%88%E6%9E%9C.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90Multi-Agent%E6%95%88%E6%9E%9C%E6%BC%94%E7%A4%BA%E6%95%88%E6%9E%9C.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63ad11-1e0d-4a9c-bfab-f2cb3e26189c",
   "metadata": {},
   "source": [
    "æ­¤å¤–ï¼Œè‹¥æ˜¯å¯¹å¤§æ¨¡å‹åº•å±‚åŸç†æ„Ÿå…´è¶£ï¼Œä¹Ÿæ¬¢è¿æŠ¥åç”±æˆ‘å’Œèœèœè€å¸ˆå…±åŒä¸»è®²çš„[ã€Š2025å¤§æ¨¡å‹åŸç†ä¸å®æˆ˜è¯¾ç¨‹ã€‹(å¤å­£ç­)](https://ix9mq.xetslk.com/s/3VITgV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc79ee-7458-4103-bc34-0b2d513dac0c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171650709.png\" alt=\"4a11b7807056e9f5b281278c0e37dad\" style=\"zoom:20%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b480939-0d7b-4205-acd3-823406118923",
   "metadata": {},
   "source": [
    "**ä¸¤é—¨å¤§æ¨¡å‹è¯¾ç¨‹å¤å­£ç­ç›®å‰ä¸Šæ–°ç‰¹æƒ +618å¹´ä¸­é’œæƒ åŒæƒ å åŠ ï¼Œåˆè´­è¿˜æœ‰æ›´å¤šä¼˜æƒ å“¦~<span style=\"color:red;\">è¯¦ç»†ä¿¡æ¯æ‰«ç æ·»åŠ åŠ©æ•™ï¼Œå›å¤â€œå¤§æ¨¡å‹â€ï¼Œå³å¯é¢†å–è¯¾ç¨‹å¤§çº²&æŸ¥çœ‹è¯¾ç¨‹è¯¦æƒ…ğŸ‘‡</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b64bf-5409-4276-a036-b6bd69040267",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171644321.jpeg\" alt=\"img\" style=\"zoom: 33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458cfda-268b-4534-9c07-f496dc607f1a",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506101749045.png\" alt=\"6d9391e440ee8df1466cef1bce40705\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271ad3a-f365-4410-ab51-0eaf2319aafe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331180f-5f74-464b-93ae-156ea561ed59",
   "metadata": {},
   "source": [
    "# <center> LangChainå¿«é€Ÿå…¥é—¨ä¸Agentå¼€å‘å®æˆ˜\n",
    "# <center> Part 7.LangChainæ¥å…¥MCPæŠ€æœ¯å®ç°æµç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21736b-d47f-4b70-99eb-9bf82824d2eb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;MCPï¼Œå…¨ç§°æ˜¯Model Context Protocolï¼Œæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼Œç”±Claudeæ¯å…¬å¸Anthropicäºå»å¹´11æœˆæ­£å¼æå‡ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfa825-63af-4334-a87f-4bdcd17d22d2",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250318201338022.png\" alt=\"image-20250318201338022\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c5b64-4210-4f5e-bf4a-57e0b4d3c7ff",
   "metadata": {},
   "source": [
    "> - Anthropic MCPå‘å¸ƒé€šå‘Šï¼šhttps://www.anthropic.com/news/model-context-protocol\n",
    "> - MCP GitHubä¸»é¡µï¼šhttps://github.com/modelcontextprotocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc7dc5-8a0e-4bee-99f5-0fedde324fe9",
   "metadata": {},
   "source": [
    "MCPçš„æ ¸å¿ƒä½œç”¨ï¼Œæ˜¯ç»Ÿä¸€äº†Agentå¼€å‘è¿‡ç¨‹ä¸­ï¼Œå¤§æ¨¡å‹è°ƒç”¨å¤–éƒ¨å·¥å…·çš„æŠ€æœ¯å®ç°æµç¨‹ï¼Œä»è€Œå¤§å¹…æé«˜Agentå¼€å‘æ•ˆç‡ã€‚åœ¨MCPè¯ç”Ÿä¹‹å‰ï¼Œä¸åŒçš„å¤–éƒ¨å·¥å…·å„æœ‰ä¸åŒçš„è°ƒç”¨æ–¹æ³•ï¼Œè¦è¿æ¥è¿™äº›å¤–éƒ¨å·¥å…·å¼€å‘Agentï¼Œå°±å¿…é¡»â€œæ¯ä¸€æŠŠé”å•ç‹¬é…ä¸€æŠŠé’¥åŒ™â€ï¼Œå¼€å‘å·¥ä½œéå¸¸ç¹çï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a85c4-bbb5-4d5e-8b8f-e73846a70512",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403170211085.png\" alt=\"image-20250403170211085\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18faecd8-9cf9-45b8-8993-55b4fd880d0d",
   "metadata": {},
   "source": [
    "è€ŒMCPçš„è¯ç”Ÿï¼Œåˆ™ç»Ÿä¸€äº†è¿™äº›å¤–éƒ¨å·¥å…·çš„è°ƒç”¨æµç¨‹ï¼Œä½¿å¾—æ— è®ºä»€ä¹ˆæ ·çš„å·¥å…·ï¼Œéƒ½å¯ä»¥å€ŸåŠ©MCPæŠ€æœ¯æŒ‰ç…§ç»Ÿä¸€çš„ä¸€ä¸ªæµç¨‹å¿«é€Ÿæ¥å…¥åˆ°å¤§æ¨¡å‹ä¸­ï¼Œä»è€Œå¤§å¹…åŠ å¿«Agentå¼€å‘æ•ˆç‡ã€‚è¿™å°±å¥½æ¯”ç°åœ¨å¾ˆå¤šè®¾å¤‡éƒ½å¯ä»¥ä½¿ç”¨type-cå’Œç”µè„‘è¿æ¥ç±»ä¼¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15868c7-439d-4815-93a8-b2cdf1027cdb",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403170238895.png\" alt=\"image-20250403170238895\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34167e06-b6ec-43dd-a2cb-c3e3b57f440e",
   "metadata": {},
   "source": [
    "ä»æŠ€æœ¯å®ç°è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†MCPçœ‹æˆæ˜¯Function callingçš„ä¸€ç§å°è£…ï¼Œé€šè¿‡server-clientæ¶æ„å’Œä¸€æ•´å¥—å¼€å‘å·¥å…·ï¼Œæ¥è§„èŒƒåŒ–Function callingå¼€å‘æµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09fb8e-707f-4995-88c6-862a9f5bb0f7",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250318202116026.png\" alt=\"image-20250318202116026\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac04bc8-aed5-4d27-9ad9-a4acd3e464f8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ­¤å‰æˆ‘å¼€è®¾è¿‡å¾ˆå¤šMCPç›¸å…³å…¬å¼€è¯¾ï¼Œåœ¨å­¦ä¹ æœ¬èŠ‚å†…å®¹å‰ï¼Œå»ºè®®å…ˆç®€å•äº†è§£MCPå®Œæ•´æŠ€æœ¯ä½“ç³»ï¼Œå¯ä»¥é€‰æ‹©ä»¥ä¸‹å…¬å¼€è¯¾è¿›è¡Œå‚è€ƒï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa582f90-d380-4441-846c-7f65b3fa39da",
   "metadata": {},
   "source": [
    "- ã€Š7åˆ†é’Ÿè®²æ¸…æ¥šMCPæ˜¯ä»€ä¹ˆï¼Ÿã€‹ï¼šhttps://www.bilibili.com/video/BV1uXQzYaEpJ/?\n",
    "- ã€ŠMCPæŠ€æœ¯å¼€å‘å…¥é—¨å®æˆ˜ï¼ã€‹ï¼šhttps://www.bilibili.com/video/BV1NLXCYTEbj/\n",
    "- ã€ŠMCPä¼ä¸šçº§æ™ºèƒ½ä½“å¼€å‘å®æˆ˜ï¼ã€‹ï¼šhttps://www.bilibili.com/video/BV1n1ZuYjEzf/\n",
    "- ã€Šä¸»æµå®¢æˆ·ç«¯æ¥å…¥MCPå®æˆ˜ã€‹ï¼šhttps://www.bilibili.com/video/BV1dCo7YdEgK/\n",
    "- ã€Šä»é›¶åˆ°ä¸€å¼€å‘&éƒ¨ç½²ä¸“å±MCPå·¥å…·ã€‹ï¼šhttps://www.bilibili.com/video/BV1VHL6zsE5F/\n",
    "- ã€Šæµå¼HTTP MCPæœåŠ¡å™¨å¼€å‘æµç¨‹ã€‹ï¼šhttps://www.bilibili.com/video/BV1P7VSzwEXL/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910a022-7471-400c-921f-80313605af74",
   "metadata": {},
   "source": [
    "MCPæŠ€æœ¯å‚è€ƒèµ„æ–™è¯¦è§å¤§æ¨¡å‹æŠ€æœ¯ç¤¾åŒºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd96ba6-48fd-4e9a-b6c2-77d9e419a5ac",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171816930.png\" alt=\"57d34aa34ec04a98b020018c55b242d\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d5845-7fac-44a7-bbad-567a3115dc78",
   "metadata": {},
   "source": [
    "### ä¸€ã€MCPåŸºç¡€å®ç°æµç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961c137-76e8-457b-afb7-83a43e74b783",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`langchain-mcp-adapters` é¡¹ç›®ä¸»è¦ä¸º`LangChain`å’Œ`LangGraph`æä¾›`MCP`çš„æ¥å…¥å’Œå…¼å®¹æ¥å£ï¼Œå…¶å·¥ä½œæµç¨‹ä¸»è¦å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a903574-cf5c-4175-834a-d1177d4537fc",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202506091749172.png\" width=\"80%\"></div>\n",
    "\n",
    "&emsp;&emsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a60f31-8ad5-4a6d-948d-4a210fff405f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å®é™…ä¸Š`load_mcp_tools()` è¿”å›çš„æ˜¯æ ‡å‡†çš„ `LangChain` å·¥å…·ï¼Œæ‰€ä»¥æ˜¯å®Œå…¨å¯ä»¥ç›´æ¥åœ¨`LangChain`ç¯å¢ƒä¸­è¿›è¡Œä½¿ç”¨çš„ã€‚åŒæ—¶ï¼Œå®Œå…¨æ”¯æŒ`stdio`ã€`Http SSE`å’Œ`Streamable HTTP`ä¸‰ç§ä¸åŒçš„é€šè®¯åè®®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec46df9-3111-4084-a6dd-48f7b5c79cc6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å…ˆå°è¯•æ‰‹åŠ¨å®ç°ä¸€é`MCP`å®è·µæµç¨‹ï¼Œç„¶åå†è€ƒè™‘å°†å·²ç»éƒ¨ç½²å¥½çš„`server`å¸¦å…¥ä¸­ï¼Œä½œä¸º`tools`è¿›è¡Œè°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effffb3b-7a50-4b5d-9b98-26f84cc835c2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸€ä¸ªæç®€çš„å¤©æ°”æŸ¥è¯¢MCPè°ƒç”¨æµç¨‹å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcd69d-fcf8-4aec-94a6-f4ac57585791",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250318172155677.png\" alt=\"image-20250318172155677\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62f749-82f6-4829-8034-c08bbd39e7f5",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506172023699.png\" alt=\"image-20250617202327646\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d07e0-68e3-4a25-a563-56b8a495fe52",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506102031014.png\" alt=\"6d9391e440ee8df1466cef1bce40705\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac601f7c-7c02-47c2-97b2-2b49343b9ff5",
   "metadata": {},
   "source": [
    "- å€ŸåŠ©uvåˆ›å»ºMCPè¿è¡Œç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cabc50-64a4-436b-a480-e16b8247b853",
   "metadata": {},
   "source": [
    "**æ–¹æ³• 1ï¼šä½¿ç”¨ `pip` å®‰è£…ï¼ˆé€‚ç”¨äºå·²å®‰è£… `pip` çš„ç³»ç»Ÿï¼‰**\n",
    "\n",
    "```bash\n",
    "pip install uv\n",
    "```\n",
    "\n",
    "**æ–¹æ³• 2ï¼šä½¿ç”¨ `curl` ç›´æ¥å®‰è£…**\n",
    "\n",
    "å¦‚æœä½ çš„ç³»ç»Ÿæ²¡æœ‰ `pip`ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œï¼š\n",
    "\n",
    "```bash\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "```\n",
    "\n",
    "è¿™ä¼šè‡ªåŠ¨ä¸‹è½½ `uv` å¹¶å®‰è£…åˆ° `/usr/local/bin`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc129a72-b7fe-410c-b777-eb2c91d46a30",
   "metadata": {},
   "source": [
    "- åˆ›å»º MCP å®¢æˆ·ç«¯é¡¹ç›®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902af937-7a18-4e59-af27-5d0ab43c150a",
   "metadata": {},
   "source": [
    "```bash\n",
    "# åˆ›å»ºé¡¹ç›®ç›®å½•\n",
    "uv init mcp-client\n",
    "cd mcp-client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1544202-244b-4f2a-a8eb-191702796d54",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202503171503701.png\" alt=\"image-20250317150300621\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d32fd2-4c93-4f02-b3a7-ebc6b0b53d09",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171833764.png\" alt=\"image-20250617183314728\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad6d61-6fab-405f-877e-9e5aede605a7",
   "metadata": {},
   "source": [
    "- åˆ›å»ºMCPå®¢æˆ·ç«¯è™šæ‹Ÿç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6aee97-d706-432d-9a9b-de7fa69ef0d9",
   "metadata": {},
   "source": [
    "```bash\n",
    "# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\n",
    "uv venv\n",
    "\n",
    "# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ\n",
    "source .venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15581215-a8ac-4a6b-97b8-d23e856c09d6",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202503171509604.png\" alt=\"image-20250317150947534\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c53da1-489e-4610-8c04-11503af2a743",
   "metadata": {},
   "source": [
    "ç„¶åå³å¯é€šè¿‡addæ–¹æ³•åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ç›¸å…³çš„åº“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fca88-633a-420f-800a-8e70766eb5d4",
   "metadata": {},
   "source": [
    "```bash\n",
    "# å®‰è£… MCP SDK\n",
    "uv add mcp openai python-dotenv httpx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1800a8dd-99a6-4da5-ac7f-6d49554c3bc6",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171833398.png\" alt=\"image-20250617183357233\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04418a9-a2d5-4024-aae2-d32c13ad51f7",
   "metadata": {},
   "source": [
    "- ç¼–å†™ç”¨äºå¤©æ°”æŸ¥è¯¢çš„serveræœåŠ¡å™¨ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a8532-61c1-4c1a-8681-51a83b7a93ce",
   "metadata": {},
   "source": [
    "è¿™é‡Œæˆ‘ä»¬éœ€è¦åœ¨æœåŠ¡å™¨ä¸Šåˆ›å»ºä¸€ä¸ªserver.pyï¼Œå¹¶å†™å…¥å¦‚ä¸‹ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd889dae-6699-4856-8a28-e0766cc524c3",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import httpx\n",
    "from typing import Any\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# åˆå§‹åŒ– MCP æœåŠ¡å™¨\n",
    "mcp = FastMCP(\"WeatherServer\")\n",
    "\n",
    "# OpenWeather API é…ç½®\n",
    "OPENWEATHER_API_BASE = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "API_KEY = \"YOUR_API_KEY\"  # è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ OpenWeather API Key\n",
    "USER_AGENT = \"weather-app/1.0\"\n",
    "\n",
    "async def fetch_weather(city: str) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    ä» OpenWeather API è·å–å¤©æ°”ä¿¡æ¯ã€‚\n",
    "    :param city: åŸå¸‚åç§°ï¼ˆéœ€ä½¿ç”¨è‹±æ–‡ï¼Œå¦‚ Beijingï¼‰\n",
    "    :return: å¤©æ°”æ•°æ®å­—å…¸ï¼›è‹¥å‡ºé”™è¿”å›åŒ…å« error ä¿¡æ¯çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"q\": city,\n",
    "        \"appid\": API_KEY,\n",
    "        \"units\": \"metric\",\n",
    "        \"lang\": \"zh_cn\"\n",
    "    }\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            response = await client.get(OPENWEATHER_API_BASE, params=params, headers=headers, timeout=30.0)\n",
    "            response.raise_for_status()\n",
    "            return response.json()  # è¿”å›å­—å…¸ç±»å‹\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            return {\"error\": f\"HTTP é”™è¯¯: {e.response.status_code}\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"è¯·æ±‚å¤±è´¥: {str(e)}\"}\n",
    "\n",
    "def format_weather(data: dict[str, Any] | str) -> str:\n",
    "    \"\"\"\n",
    "    å°†å¤©æ°”æ•°æ®æ ¼å¼åŒ–ä¸ºæ˜“è¯»æ–‡æœ¬ã€‚\n",
    "    :param data: å¤©æ°”æ•°æ®ï¼ˆå¯ä»¥æ˜¯å­—å…¸æˆ– JSON å­—ç¬¦ä¸²ï¼‰\n",
    "    :return: æ ¼å¼åŒ–åçš„å¤©æ°”ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    # å¦‚æœä¼ å…¥çš„æ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™å…ˆè½¬æ¢ä¸ºå­—å…¸\n",
    "    if isinstance(data, str):\n",
    "        try:\n",
    "            data = json.loads(data)\n",
    "        except Exception as e:\n",
    "            return f\"æ— æ³•è§£æå¤©æ°”æ•°æ®: {e}\"\n",
    "\n",
    "    # å¦‚æœæ•°æ®ä¸­åŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œç›´æ¥è¿”å›é”™è¯¯æç¤º\n",
    "    if \"error\" in data:\n",
    "        return f\"âš ï¸ {data['error']}\"\n",
    "\n",
    "    # æå–æ•°æ®æ—¶åšå®¹é”™å¤„ç†\n",
    "    city = data.get(\"name\", \"æœªçŸ¥\")\n",
    "    country = data.get(\"sys\", {}).get(\"country\", \"æœªçŸ¥\")\n",
    "    temp = data.get(\"main\", {}).get(\"temp\", \"N/A\")\n",
    "    humidity = data.get(\"main\", {}).get(\"humidity\", \"N/A\")\n",
    "    wind_speed = data.get(\"wind\", {}).get(\"speed\", \"N/A\")\n",
    "    # weather å¯èƒ½ä¸ºç©ºåˆ—è¡¨ï¼Œå› æ­¤ç”¨ [0] å‰å…ˆæä¾›é»˜è®¤å­—å…¸\n",
    "    weather_list = data.get(\"weather\", [{}])\n",
    "    description = weather_list[0].get(\"description\", \"æœªçŸ¥\")\n",
    "\n",
    "    return (\n",
    "        f\"ğŸŒ {city}, {country}\\n\"\n",
    "        f\"ğŸŒ¡ æ¸©åº¦: {temp}Â°C\\n\"\n",
    "        f\"ğŸ’§ æ¹¿åº¦: {humidity}%\\n\"\n",
    "        f\"ğŸŒ¬ é£é€Ÿ: {wind_speed} m/s\\n\"\n",
    "        f\"ğŸŒ¤ å¤©æ°”: {description}\\n\"\n",
    "    )\n",
    "\n",
    "@mcp.tool()\n",
    "async def query_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    è¾“å…¥æŒ‡å®šåŸå¸‚çš„è‹±æ–‡åç§°ï¼Œè¿”å›ä»Šæ—¥å¤©æ°”æŸ¥è¯¢ç»“æœã€‚\n",
    "    :param city: åŸå¸‚åç§°ï¼ˆéœ€ä½¿ç”¨è‹±æ–‡ï¼‰\n",
    "    :return: æ ¼å¼åŒ–åçš„å¤©æ°”ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    data = await fetch_weather(city)\n",
    "    return format_weather(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ä»¥æ ‡å‡† I/O æ–¹å¼è¿è¡Œ MCP æœåŠ¡å™¨\n",
    "    mcp.run(transport='stdio')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df50c8-1e64-4b9e-b69f-1422ee9ea8fd",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250318174907749.png\" alt=\"image-20250318174907749\" style=\"zoom: 33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f325be-6285-4c51-8142-30546aac59dc",
   "metadata": {},
   "source": [
    "- åˆ›å»ºwrite_server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d531703-f415-4ccd-8e89-d8d08b3dcbfc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸ºäº†æ›´å¥½çš„æµ‹è¯•å¤šMCPå·¥å…·è°ƒç”¨æµç¨‹ï¼Œè¿™é‡Œæˆ‘ä»¬ç»§ç»­åˆ›å»ºä¸€ä¸ªwrite_server.pyæœåŠ¡å™¨ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefe60e-6361-4416-8826-2eaeac67e626",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\r\n",
    "import httpx\r\n",
    "from typing import Any\r\n",
    "from mcp.server.fastmcp import FastMCP\r\n",
    "\r\n",
    "# åˆå§‹åŒ– MCP æœåŠ¡å™¨\r\n",
    "mcp = FastMCP(\"WriteServer\")\r\n",
    "USER_AGENT = \"write-app/1.0\"\r\n",
    "\r\n",
    "@mcp.tool()\r\n",
    "async def write_file(content: str) -> str:\r\n",
    "    \"\"\"\r\n",
    "    å°†æŒ‡å®šå†…å®¹å†™å…¥æœ¬åœ°æ–‡ä»¶ã€‚\r\n",
    "    :param content: å¿…è¦å‚æ•°ï¼Œå­—ç¬¦ä¸²ç±»å‹ï¼Œç”¨äºè¡¨ç¤ºéœ€è¦å†™å…¥æ–‡æ¡£çš„å…·ä½“å†…å®¹ã€‚\r\n",
    "    :returnï¼šæ˜¯å¦æˆåŠŸå†™å…¥\r\n",
    "    \"\"\"\r\n",
    "    return \"å·²æˆåŠŸå†™å…¥æœ¬åœ°æ–‡ä»¶ã€‚\"\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    # ä»¥æ ‡å‡† I/O æ–¹å¼è¿è¡Œ MCP æœåŠ¡å™¨\r\n",
    "    mcp.run(transport='stdio')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340ac06-de3f-4b94-b7b5-a898c156de97",
   "metadata": {},
   "source": [
    "- å¤©æ°”æŸ¥è¯¢å®¢æˆ·ç«¯clientåˆ›å»ºæµç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf8606-20cc-4ac1-bd3f-59edc777def6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ç„¶ååˆ›å»ºä¸€ä¸ªå¯ä»¥å’Œserverè¿›è¡Œé€šä¿¡çš„å®¢æˆ·ç«¯ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¯¥å®¢æˆ·ç«¯éœ€è¦åŒ…å«å¤§æ¨¡å‹è°ƒç”¨çš„åŸºç¡€ä¿¡æ¯ã€‚æˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ªclient.pyè„šæœ¬ï¼Œè¿™ä¸ªè„šæœ¬å†…å®¹éå¸¸å¤æ‚ï¼Œå®Œæ•´ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51602d5c-2da2-401b-bf8c-0e6aedd2af9a",
   "metadata": {},
   "source": [
    "```python\n",
    "import asyncio\r\n",
    "import json\r\n",
    "import logging\r\n",
    "import os\r\n",
    "import shutil\r\n",
    "from contextlib import AsyncExitStack\r\n",
    "from typing import Any, Dict, List, Optional\r\n",
    "\r\n",
    "import httpx\r\n",
    "from dotenv import load_dotenv\r\n",
    "from openai import OpenAI  # OpenAI Python SDK\r\n",
    "from mcp import ClientSession, StdioServerParameters\r\n",
    "from mcp.client.stdio import stdio_client\r\n",
    "\r\n",
    "# Configure logging\r\n",
    "logging.basicConfig(\r\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "# =============================\r\n",
    "# é…ç½®åŠ è½½ç±»ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡åŠé…ç½®æ–‡ä»¶ï¼‰\r\n",
    "# =============================\r\n",
    "class Configuration:\r\n",
    "    \"\"\"ç®¡ç† MCP å®¢æˆ·ç«¯çš„ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶\"\"\"\r\n",
    "\r\n",
    "    def __init__(self) -> None:\r\n",
    "        load_dotenv()\r\n",
    "        # ä»ç¯å¢ƒå˜é‡ä¸­åŠ è½½ API key, base_url å’Œ model\r\n",
    "        self.api_key = os.getenv(\"LLM_API_KEY\")\r\n",
    "        self.base_url = os.getenv(\"BASE_URL\")\r\n",
    "        self.model = os.getenv(\"MODEL\")\r\n",
    "        if not self.api_key:\r\n",
    "            raise ValueError(\"âŒ æœªæ‰¾åˆ° LLM_API_KEYï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®\")\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def load_config(file_path: str) -> Dict[str, Any]:\r\n",
    "        \"\"\"\r\n",
    "        ä» JSON æ–‡ä»¶åŠ è½½æœåŠ¡å™¨é…ç½®\r\n",
    "        \r\n",
    "        Args:\r\n",
    "            file_path: JSON é…ç½®æ–‡ä»¶è·¯å¾„\r\n",
    "        \r\n",
    "        Returns:\r\n",
    "            åŒ…å«æœåŠ¡å™¨é…ç½®çš„å­—å…¸\r\n",
    "        \"\"\"\r\n",
    "        with open(file_path, \"r\") as f:\r\n",
    "            return json.load(f)\r\n",
    "\r\n",
    "\r\n",
    "# =============================\r\n",
    "# MCP æœåŠ¡å™¨å®¢æˆ·ç«¯ç±»\r\n",
    "# =============================\r\n",
    "class Server:\r\n",
    "    \"\"\"ç®¡ç†å•ä¸ª MCP æœåŠ¡å™¨è¿æ¥å’Œå·¥å…·è°ƒç”¨\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, name: str, config: Dict[str, Any]) -> None:\r\n",
    "        self.name: str = name\r\n",
    "        self.config: Dict[str, Any] = config\r\n",
    "        self.session: Optional[ClientSession] = None\r\n",
    "        self.exit_stack: AsyncExitStack = AsyncExitStack()\r\n",
    "        self._cleanup_lock = asyncio.Lock()\r\n",
    "\r\n",
    "    async def initialize(self) -> None:\r\n",
    "        \"\"\"åˆå§‹åŒ–ä¸ MCP æœåŠ¡å™¨çš„è¿æ¥\"\"\"\r\n",
    "        # command å­—æ®µç›´æ¥ä»é…ç½®è·å–\r\n",
    "        command = self.config[\"command\"]\r\n",
    "        if command is None:\r\n",
    "            raise ValueError(\"command ä¸èƒ½ä¸ºç©º\")\r\n",
    "\r\n",
    "        server_params = StdioServerParameters(\r\n",
    "            command=command,\r\n",
    "            args=self.config[\"args\"],\r\n",
    "            env={**os.environ, **self.config[\"env\"]} if self.config.get(\"env\") else None,\r\n",
    "        )\r\n",
    "        try:\r\n",
    "            stdio_transport = await self.exit_stack.enter_async_context(\r\n",
    "                stdio_client(server_params)\r\n",
    "            )\r\n",
    "            read_stream, write_stream = stdio_transport\r\n",
    "            session = await self.exit_stack.enter_async_context(\r\n",
    "                ClientSession(read_stream, write_stream)\r\n",
    "            )\r\n",
    "            await session.initialize()\r\n",
    "            self.session = session\r\n",
    "        except Exception as e:\r\n",
    "            logging.error(f\"Error initializing server {self.name}: {e}\")\r\n",
    "            await self.cleanup()\r\n",
    "            raise\r\n",
    "\r\n",
    "    async def list_tools(self) -> List[Any]:\r\n",
    "        \"\"\"è·å–æœåŠ¡å™¨å¯ç”¨çš„å·¥å…·åˆ—è¡¨\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            å·¥å…·åˆ—è¡¨\r\n",
    "        \"\"\"\r\n",
    "        if not self.session:\r\n",
    "            raise RuntimeError(f\"Server {self.name} not initialized\")\r\n",
    "        tools_response = await self.session.list_tools()\r\n",
    "        tools = []\r\n",
    "        for item in tools_response:\r\n",
    "            if isinstance(item, tuple) and item[0] == \"tools\":\r\n",
    "                for tool in item[1]:\r\n",
    "                    tools.append(Tool(tool.name, tool.description, tool.inputSchema))\r\n",
    "        return tools\r\n",
    "\r\n",
    "    async def execute_tool(\r\n",
    "        self, tool_name: str, arguments: Dict[str, Any], retries: int = 2, delay: float = 1.0\r\n",
    "    ) -> Any:\r\n",
    "        \"\"\"æ‰§è¡ŒæŒ‡å®šå·¥å…·ï¼Œå¹¶æ”¯æŒé‡è¯•æœºåˆ¶\r\n",
    "\r\n",
    "        Args:\r\n",
    "            tool_name: å·¥å…·åç§°\r\n",
    "            arguments: å·¥å…·å‚æ•°\r\n",
    "            retries: é‡è¯•æ¬¡æ•°\r\n",
    "            delay: é‡è¯•é—´éš”ç§’æ•°\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            å·¥å…·è°ƒç”¨ç»“æœ\r\n",
    "        \"\"\"\r\n",
    "        if not self.session:\r\n",
    "            raise RuntimeError(f\"Server {self.name} not initialized\")\r\n",
    "        attempt = 0\r\n",
    "        while attempt < retries:\r\n",
    "            try:\r\n",
    "                logging.info(f\"Executing {tool_name} on server {self.name}...\")\r\n",
    "                result = await self.session.call_tool(tool_name, arguments)\r\n",
    "                return result\r\n",
    "            except Exception as e:\r\n",
    "                attempt += 1\r\n",
    "                logging.warning(\r\n",
    "                    f\"Error executing tool: {e}. Attempt {attempt} of {retries}.\"\r\n",
    "                )\r\n",
    "                if attempt < retries:\r\n",
    "                    logging.info(f\"Retrying in {delay} seconds...\")\r\n",
    "                    await asyncio.sleep(delay)\r\n",
    "                else:\r\n",
    "                    logging.error(\"Max retries reached. Failing.\")\r\n",
    "                    raise\r\n",
    "\r\n",
    "    async def cleanup(self) -> None:\r\n",
    "        \"\"\"æ¸…ç†æœåŠ¡å™¨èµ„æº\"\"\"\r\n",
    "        async with self._cleanup_lock:\r\n",
    "            try:\r\n",
    "                await self.exit_stack.aclose()\r\n",
    "                self.session = None\r\n",
    "            except Exception as e:\r\n",
    "                logging.error(f\"Error during cleanup of server {self.name}: {e}\")\r\n",
    "\r\n",
    "\r\n",
    "# =============================\r\n",
    "# å·¥å…·å°è£…ç±»\r\n",
    "# =============================\r\n",
    "class Tool:\r\n",
    "    \"\"\"å°è£… MCP è¿”å›çš„å·¥å…·ä¿¡æ¯\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, name: str, description: str, input_schema: Dict[str, Any]) -> None:\r\n",
    "        self.name: str = name\r\n",
    "        self.description: str = description\r\n",
    "        self.input_schema: Dict[str, Any] = input_schema\r\n",
    "\r\n",
    "    def format_for_llm(self) -> str:\r\n",
    "        \"\"\"ç”Ÿæˆç”¨äº LLM æç¤ºçš„å·¥å…·æè¿°\"\"\"\r\n",
    "        args_desc = []\r\n",
    "        if \"properties\" in self.input_schema:\r\n",
    "            for param_name, param_info in self.input_schema[\"properties\"].items():\r\n",
    "                arg_desc = f\"- {param_name}: {param_info.get('description', 'No description')}\"\r\n",
    "                if param_name in self.input_schema.get(\"required\", []):\r\n",
    "                    arg_desc += \" (required)\"\r\n",
    "                args_desc.append(arg_desc)\r\n",
    "        return f\"\"\"\r\n",
    "Tool: {self.name}\r\n",
    "Description: {self.description}\r\n",
    "Arguments:\r\n",
    "{chr(10).join(args_desc)}\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "# =============================\r\n",
    "# LLM å®¢æˆ·ç«¯å°è£…ç±»ï¼ˆä½¿ç”¨ OpenAI SDKï¼‰\r\n",
    "# =============================\r\n",
    "class LLMClient:\r\n",
    "    \"\"\"ä½¿ç”¨ OpenAI SDK ä¸å¤§æ¨¡å‹äº¤äº’\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, api_key: str, base_url: Optional[str], model: str) -> None:\r\n",
    "        self.client = OpenAI(api_key=api_key, base_url=base_url)\r\n",
    "        self.model = model\r\n",
    "\r\n",
    "    def get_response(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = None) -> Any:\r\n",
    "        \"\"\"\r\n",
    "        å‘é€æ¶ˆæ¯ç»™å¤§æ¨¡å‹ APIï¼Œæ”¯æŒä¼ å…¥å·¥å…·å‚æ•°ï¼ˆfunction calling æ ¼å¼ï¼‰\r\n",
    "        \"\"\"\r\n",
    "        payload = {\r\n",
    "            \"model\": self.model,\r\n",
    "            \"messages\": messages,\r\n",
    "            \"tools\": tools,\r\n",
    "        }\r\n",
    "        try:\r\n",
    "            response = self.client.chat.completions.create(**payload)\r\n",
    "            return response\r\n",
    "        except Exception as e:\r\n",
    "            logging.error(f\"Error during LLM call: {e}\")\r\n",
    "            raise\r\n",
    "\r\n",
    "\r\n",
    "# =============================\r\n",
    "# å¤šæœåŠ¡å™¨ MCP å®¢æˆ·ç«¯ç±»ï¼ˆé›†æˆé…ç½®æ–‡ä»¶ã€å·¥å…·æ ¼å¼è½¬æ¢ä¸ OpenAI SDK è°ƒç”¨ï¼‰\r\n",
    "# =============================\r\n",
    "class MultiServerMCPClient:\r\n",
    "    def __init__(self) -> None:\r\n",
    "        \"\"\"\r\n",
    "        ç®¡ç†å¤šä¸ª MCP æœåŠ¡å™¨ï¼Œå¹¶ä½¿ç”¨ OpenAI Function Calling é£æ ¼çš„æ¥å£è°ƒç”¨å¤§æ¨¡å‹\r\n",
    "        \"\"\"\r\n",
    "        self.exit_stack = AsyncExitStack()\r\n",
    "        config = Configuration()\r\n",
    "        self.openai_api_key = config.api_key\r\n",
    "        self.base_url = config.base_url\r\n",
    "        self.model = config.model\r\n",
    "        self.client = LLMClient(self.openai_api_key, self.base_url, self.model)\r\n",
    "        # (server_name -> Server å¯¹è±¡)\r\n",
    "        self.servers: Dict[str, Server] = {}\r\n",
    "        # å„ä¸ª server çš„å·¥å…·åˆ—è¡¨\r\n",
    "        self.tools_by_server: Dict[str, List[Any]] = {}\r\n",
    "        self.all_tools: List[Dict[str, Any]] = []\r\n",
    "\r\n",
    "    async def connect_to_servers(self, servers_config: Dict[str, Any]) -> None:\r\n",
    "        \"\"\"\r\n",
    "        æ ¹æ®é…ç½®æ–‡ä»¶åŒæ—¶å¯åŠ¨å¤šä¸ªæœåŠ¡å™¨å¹¶è·å–å·¥å…·\r\n",
    "        servers_config çš„æ ¼å¼ä¸ºï¼š\r\n",
    "        {\r\n",
    "          \"mcpServers\": {\r\n",
    "              \"sqlite\": { \"command\": \"uvx\", \"args\": [ ... ] },\r\n",
    "              \"puppeteer\": { \"command\": \"npx\", \"args\": [ ... ] },\r\n",
    "              ...\r\n",
    "          }\r\n",
    "        }\r\n",
    "        \"\"\"\r\n",
    "        mcp_servers = servers_config.get(\"mcpServers\", {})\r\n",
    "        for server_name, srv_config in mcp_servers.items():\r\n",
    "            server = Server(server_name, srv_config)\r\n",
    "            await server.initialize()\r\n",
    "            self.servers[server_name] = server\r\n",
    "            tools = await server.list_tools()\r\n",
    "            self.tools_by_server[server_name] = tools\r\n",
    "\r\n",
    "            for tool in tools:\r\n",
    "                # ç»Ÿä¸€é‡å‘½åï¼šserverName_toolName\r\n",
    "                function_name = f\"{server_name}_{tool.name}\"\r\n",
    "                self.all_tools.append({\r\n",
    "                    \"type\": \"function\",\r\n",
    "                    \"function\": {\r\n",
    "                        \"name\": function_name,\r\n",
    "                        \"description\": tool.description,\r\n",
    "                        \"input_schema\": tool.input_schema\r\n",
    "                    }\r\n",
    "                })\r\n",
    "\r\n",
    "        # è½¬æ¢ä¸º OpenAI Function Calling æ‰€éœ€æ ¼å¼\r\n",
    "        self.all_tools = await self.transform_json(self.all_tools)\r\n",
    "\r\n",
    "        logging.info(\"\\nâœ… å·²è¿æ¥åˆ°ä¸‹åˆ—æœåŠ¡å™¨:\")\r\n",
    "        for name in self.servers:\r\n",
    "            srv_cfg = mcp_servers[name]\r\n",
    "            logging.info(f\"  - {name}: command={srv_cfg['command']}, args={srv_cfg['args']}\")\r\n",
    "        logging.info(\"\\næ±‡æ€»çš„å·¥å…·:\")\r\n",
    "        for t in self.all_tools:\r\n",
    "            logging.info(f\"  - {t['function']['name']}\")\r\n",
    "\r\n",
    "    async def transform_json(self, json_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\r\n",
    "        \"\"\"\r\n",
    "        å°†å·¥å…·çš„ input_schema è½¬æ¢ä¸º OpenAI æ‰€éœ€çš„ parameters æ ¼å¼ï¼Œå¹¶åˆ é™¤å¤šä½™å­—æ®µ\r\n",
    "        \"\"\"\r\n",
    "        result = []\r\n",
    "        for item in json_data:\r\n",
    "            if not isinstance(item, dict) or \"type\" not in item or \"function\" not in item:\r\n",
    "                continue\r\n",
    "            old_func = item[\"function\"]\r\n",
    "            if not isinstance(old_func, dict) or \"name\" not in old_func or \"description\" not in old_func:\r\n",
    "                continue\r\n",
    "            new_func = {\r\n",
    "                \"name\": old_func[\"name\"],\r\n",
    "                \"description\": old_func[\"description\"],\r\n",
    "                \"parameters\": {}\r\n",
    "            }\r\n",
    "            if \"input_schema\" in old_func and isinstance(old_func[\"input_schema\"], dict):\r\n",
    "                old_schema = old_func[\"input_schema\"]\r\n",
    "                new_func[\"parameters\"][\"type\"] = old_schema.get(\"type\", \"object\")\r\n",
    "                new_func[\"parameters\"][\"properties\"] = old_schema.get(\"properties\", {})\r\n",
    "                new_func[\"parameters\"][\"required\"] = old_schema.get(\"required\", [])\r\n",
    "            new_item = {\r\n",
    "                \"type\": item[\"type\"],\r\n",
    "                \"function\": new_func\r\n",
    "            }\r\n",
    "            result.append(new_item)\r\n",
    "        return result\r\n",
    "\r\n",
    "    async def chat_base(self, messages: List[Dict[str, Any]]) -> Any:\r\n",
    "        \"\"\"\r\n",
    "        ä½¿ç”¨ OpenAI æ¥å£è¿›è¡Œå¯¹è¯ï¼Œå¹¶æ”¯æŒå¤šæ¬¡å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰ã€‚\r\n",
    "        å¦‚æœè¿”å› finish_reason ä¸º \"tool_calls\"ï¼Œåˆ™è¿›è¡Œå·¥å…·è°ƒç”¨åå†å‘èµ·è¯·æ±‚ã€‚\r\n",
    "        \"\"\"\r\n",
    "        response = self.client.get_response(messages, tools=self.all_tools)\r\n",
    "        # å¦‚æœæ¨¡å‹è¿”å›å·¥å…·è°ƒç”¨\r\n",
    "        if response.choices[0].finish_reason == \"tool_calls\":\r\n",
    "            while True:\r\n",
    "                messages = await self.create_function_response_messages(messages, response)\r\n",
    "                response = self.client.get_response(messages, tools=self.all_tools)\r\n",
    "                if response.choices[0].finish_reason != \"tool_calls\":\r\n",
    "                    break\r\n",
    "        return response\r\n",
    "\r\n",
    "    async def create_function_response_messages(self, messages: List[Dict[str, Any]], response: Any) -> List[Dict[str, Any]]:\r\n",
    "        \"\"\"\r\n",
    "        å°†æ¨¡å‹è¿”å›çš„å·¥å…·è°ƒç”¨è§£ææ‰§è¡Œï¼Œå¹¶å°†ç»“æœè¿½åŠ åˆ°æ¶ˆæ¯é˜Ÿåˆ—ä¸­\r\n",
    "        \"\"\"\r\n",
    "        function_call_messages = response.choices[0].message.tool_calls\r\n",
    "        messages.append(response.choices[0].message.model_dump())\r\n",
    "        for function_call_message in function_call_messages:\r\n",
    "            tool_name = function_call_message.function.name\r\n",
    "            tool_args = json.loads(function_call_message.function.arguments)\r\n",
    "            # è°ƒç”¨ MCP å·¥å…·\r\n",
    "            function_response = await self._call_mcp_tool(tool_name, tool_args)\r\n",
    "            # ğŸ” æ‰“å°è¿”å›å€¼åŠå…¶ç±»å‹\r\n",
    "            # print(f\"[DEBUG] tool_name: {tool_name}\")\r\n",
    "            # print(f\"[DEBUG] tool_args: {tool_args}\")\r\n",
    "            # print(f\"[DEBUG] function_response: {function_response}\")\r\n",
    "            # print(f\"[DEBUG] type(function_response): {type(function_response)}\")\r\n",
    "            messages.append({\r\n",
    "                \"role\": \"tool\",\r\n",
    "                \"content\": function_response,\r\n",
    "                \"tool_call_id\": function_call_message.id,\r\n",
    "            })\r\n",
    "        return messages\r\n",
    "\r\n",
    "    async def process_query(self, user_query: str) -> str:\r\n",
    "        \"\"\"\r\n",
    "        OpenAI Function Calling æµç¨‹ï¼š\r\n",
    "         1. å‘é€ç”¨æˆ·æ¶ˆæ¯ + å·¥å…·ä¿¡æ¯\r\n",
    "         2. è‹¥æ¨¡å‹è¿”å› finish_reason ä¸º \"tool_calls\"ï¼Œåˆ™è§£æå¹¶è°ƒç”¨ MCP å·¥å…·\r\n",
    "         3. å°†å·¥å…·è°ƒç”¨ç»“æœè¿”å›ç»™æ¨¡å‹ï¼Œè·å¾—æœ€ç»ˆå›ç­”\r\n",
    "        \"\"\"\r\n",
    "        messages = [{\"role\": \"user\", \"content\": user_query}]\r\n",
    "        response = self.client.get_response(messages, tools=self.all_tools)\r\n",
    "        content = response.choices[0]\r\n",
    "        logging.info(content)\r\n",
    "        if content.finish_reason == \"tool_calls\":\r\n",
    "            tool_call = content.message.tool_calls[0]\r\n",
    "            tool_name = tool_call.function.name\r\n",
    "            tool_args = json.loads(tool_call.function.arguments)\r\n",
    "            logging.info(f\"\\n[ è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {tool_args} ]\\n\")\r\n",
    "            result = await self._call_mcp_tool(tool_name, tool_args)\r\n",
    "            messages.append(content.message.model_dump())\r\n",
    "            messages.append({\r\n",
    "                \"role\": \"tool\",\r\n",
    "                \"content\": result,\r\n",
    "                \"tool_call_id\": tool_call.id,\r\n",
    "            })\r\n",
    "            response = self.client.get_response(messages, tools=self.all_tools)\r\n",
    "            return response.choices[0].message.content\r\n",
    "        return content.message.content\r\n",
    "\r\n",
    "    async def _call_mcp_tool(self, tool_full_name: str, tool_args: Dict[str, Any]) -> str:\r\n",
    "        \"\"\"\r\n",
    "        æ ¹æ® \"serverName_toolName\" æ ¼å¼è°ƒç”¨ç›¸åº” MCP å·¥å…·\r\n",
    "        \"\"\"\r\n",
    "        parts = tool_full_name.split(\"_\", 1)\r\n",
    "        if len(parts) != 2:\r\n",
    "            return f\"æ— æ•ˆçš„å·¥å…·åç§°: {tool_full_name}\"\r\n",
    "        server_name, tool_name = parts\r\n",
    "        server = self.servers.get(server_name)\r\n",
    "        if not server:\r\n",
    "            return f\"æ‰¾ä¸åˆ°æœåŠ¡å™¨: {server_name}\"\r\n",
    "        resp = await server.execute_tool(tool_name, tool_args)\r\n",
    "        \r\n",
    "        # ğŸ› ï¸ ä¿®å¤ç‚¹ï¼šæå– TextContent ä¸­çš„æ–‡æœ¬ï¼ˆæˆ–è½¬æˆå­—ç¬¦ä¸²ï¼‰\r\n",
    "        content = resp.content\r\n",
    "        if isinstance(content, list):\r\n",
    "            # æå–æ‰€æœ‰ TextContent å¯¹è±¡ä¸­çš„ text å­—æ®µ\r\n",
    "            texts = [c.text for c in content if hasattr(c, \"text\")]\r\n",
    "            return \"\\n\".join(texts)\r\n",
    "        elif isinstance(content, dict) or isinstance(content, list):\r\n",
    "            # å¦‚æœæ˜¯ dict æˆ– listï¼Œä½†ä¸æ˜¯ TextContent ç±»å‹\r\n",
    "            return json.dumps(content, ensure_ascii=False)\r\n",
    "        elif content is None:\r\n",
    "            return \"å·¥å…·æ‰§è¡Œæ— è¾“å‡º\"\r\n",
    "        else:\r\n",
    "            return str(content)\r\n",
    "\r\n",
    "    async def chat_loop(self) -> None:\r\n",
    "        \"\"\"å¤šæœåŠ¡å™¨ MCP + OpenAI Function Calling å®¢æˆ·ç«¯ä¸»å¾ªç¯\"\"\"\r\n",
    "        logging.info(\"\\nğŸ¤– å¤šæœåŠ¡å™¨ MCP + Function Calling å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡ºã€‚\")\r\n",
    "        messages: List[Dict[str, Any]] = []\r\n",
    "        while True:\r\n",
    "            query = input(\"\\nä½ : \").strip()\r\n",
    "            if query.lower() == \"quit\":\r\n",
    "                break\r\n",
    "            try:\r\n",
    "                messages.append({\"role\": \"user\", \"content\": query})\r\n",
    "                messages = messages[-20:]  # ä¿æŒæœ€æ–° 20 æ¡ä¸Šä¸‹æ–‡\r\n",
    "                response = await self.chat_base(messages)\r\n",
    "                messages.append(response.choices[0].message.model_dump())\r\n",
    "                result = response.choices[0].message.content\r\n",
    "                # logging.info(f\"\\nAI: {result}\")\r\n",
    "                print(f\"\\nAI: {result}\")\r\n",
    "            except Exception as e:\r\n",
    "                print(f\"\\nâš ï¸  è°ƒç”¨è¿‡ç¨‹å‡ºé”™: {e}\")\r\n",
    "\r\n",
    "    async def cleanup(self) -> None:\r\n",
    "        \"\"\"å…³é—­æ‰€æœ‰èµ„æº\"\"\"\r\n",
    "        await self.exit_stack.aclose()\r\n",
    "\r\n",
    "\r\n",
    "# =============================\r\n",
    "# ä¸»å‡½æ•°\r\n",
    "# =============================\r\n",
    "async def main() -> None:\r\n",
    "    # ä»é…ç½®æ–‡ä»¶åŠ è½½æœåŠ¡å™¨é…ç½®\r\n",
    "    config = Configuration()\r\n",
    "    servers_config = config.load_config(\"servers_config.json\")\r\n",
    "    client = MultiServerMCPClient()\r\n",
    "    try:\r\n",
    "        await client.connect_to_servers(servers_config)\r\n",
    "        await client.chat_loop()\r\n",
    "    finally:\r\n",
    "        try:\r\n",
    "            await asyncio.sleep(0.1)\r\n",
    "            await client.cleanup()\r\n",
    "        except RuntimeError as e:\r\n",
    "            # å¦‚æœæ˜¯å› ä¸ºé€€å‡º cancel scope å¯¼è‡´çš„å¼‚å¸¸ï¼Œå¯ä»¥é€‰æ‹©å¿½ç•¥\r\n",
    "            if \"Attempted to exit cancel scope\" in str(e):\r\n",
    "                logging.info(\"é€€å‡ºæ—¶æ£€æµ‹åˆ° cancel scope å¼‚å¸¸ï¼Œå·²å¿½ç•¥ã€‚\")\r\n",
    "            else:\r\n",
    "                raise\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    asyncio.run(main())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acaa29e-e3db-4196-ab43-4346782fa365",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/1742291307705.jpg\" alt=\"1742291307705\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635253a-07ed-4f9b-ab5b-2f287a6c8e4a",
   "metadata": {},
   "source": [
    "- åˆ›å»º.envæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec040873-757e-4688-b015-e1e84ff79a41",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ¥ä¸‹æ¥ç»§ç»­åˆ›å»ºä¸€ä¸ª`.env`æ–‡ä»¶ï¼Œæ¥ä¿å­˜å¤§æ¨¡å‹è°ƒç”¨çš„API-KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee8821b-e0d6-4372-9bb8-b2738e1ee006",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202503171539087.png\" alt=\"image-20250317153902986\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297a066-b5e5-44ee-b07c-abd911c6380a",
   "metadata": {},
   "source": [
    "å¹¶å†™å…¥å¦‚ä¸‹å†…å®¹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7250f-67f1-49f7-a77f-3efc58186218",
   "metadata": {},
   "source": [
    "```bash\n",
    "BASE_URL=https://api.deepseek.com\n",
    "MODEL=deepseek-chat\n",
    "OPENAI_API_KEY=YOUR_DEEPSEEK_API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1346ce7-ab4e-4aac-bf55-a74d123fd40b",
   "metadata": {},
   "source": [
    "- åˆ›å»ºservers_config.jsonæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617a4d4-f260-49e0-a1ba-2e166efee62c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ¥ä¸‹æ¥ç»§ç»­åˆ›å»ºservers_config.jsonæ–‡ä»¶ï¼Œç”¨äºä¿å­˜MCPå·¥å…·åŸºæœ¬ä¿¡æ¯ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc973d-67fc-426d-934c-b244703e3488",
   "metadata": {},
   "source": [
    "```json\n",
    "{\r\n",
    "  \"mcpServers\": {\r\n",
    "    \"weather\": {\r\n",
    "      \"command\": \"python\",\r\n",
    "      \"args\": [\"weather_server.py\"],\r\n",
    "      \"transport\": \"stdio\"\r\n",
    "    },\r\n",
    "    \"write\": {\r\n",
    "      \"command\": \"python\",\r\n",
    "      \"args\": [\"write_server.py\"],\r\n",
    "      \"transport\": \"stdio\"\r\n",
    " ```   }\r\n",
    "  }\r\n",
    "}\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8032b7-fa49-4d5e-8bd2-296b1352b5aa",
   "metadata": {},
   "source": [
    "æ­¤æ—¶å®Œæ•´é¡¹ç›®ç»“æ„å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003932f1-632c-49fb-8534-68c9d4ff37e0",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506172025805.png\" alt=\"image-20250617202549758\" style=\"zoom: 33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21516da1-8724-4eea-b82d-fa7d5ad6bb44",
   "metadata": {},
   "source": [
    "- è¿è¡ŒMCPå®¢æˆ·ç«¯+æœåŠ¡å™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c246ca-b135-42ba-900e-0ea859325214",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æœ€ååœ¨å‘½ä»¤è¡Œä¸­æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œå³å¯å¼€å¯å¯¹è¯ï¼š\n",
    "\n",
    "```bash\n",
    "uv run client.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5fd4f-f991-427d-9b40-296073bdc92b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171855700.png\" alt=\"image-20250617185517285\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f96a89-07b6-4cec-b26b-c4e10ded33a4",
   "metadata": {},
   "source": [
    "è‡³æ­¤ï¼Œå³å®Œæˆäº†ä¸€æ¬¡ç®€å•çš„MCPæ‰§è¡Œæµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1817b-be9f-49ce-a806-04097d31d618",
   "metadata": {},
   "source": [
    "## 3.4 MCP+LangChainåŸºç¡€è°ƒç”¨æµç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914408c8-3ec0-43a8-ac27-4bfe69941953",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`LangChain`è°ƒç”¨`MCP`æ˜¯å¯ä»¥å°†`MCP`çš„å·¥å…·ç›´æ¥è½¬æ¢ä¸º`LangChain`çš„å·¥å…·ï¼Œç„¶åé€šè¿‡é¢„å®šä¹‰çš„`MCP_Client`å®ç°ä¸å¤–éƒ¨`MCP`çš„è¯»å†™æ“ä½œï¼Œæ¢è€Œè¨€ä¹‹å°±æ˜¯æˆ‘ä»¬éœ€è¦æ”¹å†™åŸå…ˆçš„clientï¼Œå°†åŸå…ˆçš„Function callingè°ƒç”¨é€»è¾‘ä¿®æ”¹ä¸ºLangChainè°ƒç”¨é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb57530-3adb-493e-b56e-e4f0b8171f69",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506172028187.png\" alt=\"image-20250617202831129\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d0934-e957-4893-bbb8-d288c69cf93d",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"\r\n",
    "å¤šæœåŠ¡å™¨ MCP + LangChain Agent ç¤ºä¾‹\r\n",
    "---------------------------------\r\n",
    "1. è¯»å– .env ä¸­çš„ LLM_API_KEY / BASE_URL / MODEL\r\n",
    "2. è¯»å– servers_config.json ä¸­çš„ MCP æœåŠ¡å™¨ä¿¡æ¯\r\n",
    "3. å¯åŠ¨ MCP æœåŠ¡å™¨ï¼ˆæ”¯æŒå¤šä¸ªï¼‰\r\n",
    "4. å°†æ‰€æœ‰å·¥å…·æ³¨å…¥ LangChain Agentï¼Œç”±å¤§æ¨¡å‹è‡ªåŠ¨é€‰æ‹©å¹¶è°ƒç”¨\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "import asyncio\r\n",
    "import json\r\n",
    "import logging\r\n",
    "import os\r\n",
    "from typing import Any, Dict, List\r\n",
    "\r\n",
    "from dotenv import load_dotenv\r\n",
    "from langchain import hub\r\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\r\n",
    "from langchain.chat_models import init_chat_model\r\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\r\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\r\n",
    "\r\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
    "# ç¯å¢ƒé…ç½®\r\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
    "\r\n",
    "class Configuration:\r\n",
    "    \"\"\"è¯»å– .env ä¸ servers_config.json\"\"\"\r\n",
    "\r\n",
    "    def __init__(self) -> None:\r\n",
    "        load_dotenv()\r\n",
    "        self.api_key: str = os.getenv(\"LLM_API_KEY\") or \"\"\r\n",
    "        self.base_url: str | None = os.getenv(\"BASE_URL\")  # DeepSeek ç”¨ https://api.deepseek.com\r\n",
    "        self.model: str = os.getenv(\"MODEL\") or \"deepseek-chat\"\r\n",
    "        if not self.api_key:\r\n",
    "            raise ValueError(\"âŒ æœªæ‰¾åˆ° LLM_API_KEYï¼Œè¯·åœ¨ .env ä¸­é…ç½®\")\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def load_servers(file_path: str = \"servers_config.json\") -> Dict[str, Any]:\r\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\r\n",
    "            return json.load(f).get(\"mcpServers\", {})\r\n",
    "\r\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
    "# ä¸»é€»è¾‘\r\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
    "async def run_chat_loop() -> None:\r\n",
    "    \"\"\"å¯åŠ¨ MCP-Agent èŠå¤©å¾ªç¯\"\"\"\r\n",
    "    cfg = Configuration()\r\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = os.getenv(\"LLM_API_KEY\", \"\")\r\n",
    "    if cfg.base_url:\r\n",
    "        os.environ[\"DEEPSEEK_API_BASE\"] = cfg.base_url\r\n",
    "    servers_cfg = Configuration.load_servers()\r\n",
    "\r\n",
    "    # æŠŠ key æ³¨å…¥ç¯å¢ƒï¼ŒLangChain-OpenAI / DeepSeek ä¼šè‡ªåŠ¨è¯»å–\r\n",
    "    os.environ[\"OPENAI_API_KEY\"] = cfg.api_key\r\n",
    "    if cfg.base_url:  # å¯¹ DeepSeek ä¹‹ç±»çš„è‡ªå®šä¹‰åŸŸåå¾ˆæœ‰ç”¨\r\n",
    "        os.environ[\"OPENAI_BASE_URL\"] = cfg.base_url\r\n",
    "\r\n",
    "    # 1ï¸âƒ£ è¿æ¥å¤šå° MCP æœåŠ¡å™¨\r\n",
    "    mcp_client = MultiServerMCPClient(servers_cfg)\r\n",
    "\r\n",
    "    tools = await mcp_client.get_tools()         # LangChain Tool å¯¹è±¡åˆ—è¡¨\r\n",
    "\r\n",
    "    logging.info(f\"âœ… å·²åŠ è½½ {len(tools)} ä¸ª MCP å·¥å…·ï¼š {[t.name for t in tools]}\")\r\n",
    "\r\n",
    "    # 2ï¸âƒ£ åˆå§‹åŒ–å¤§æ¨¡å‹ï¼ˆDeepSeek / OpenAI / ä»»æ„å…¼å®¹ OpenAI åè®®çš„æ¨¡å‹ï¼‰\r\n",
    "    llm = init_chat_model(\r\n",
    "        model=cfg.model,\r\n",
    "        model_provider=\"deepseek\" if \"deepseek\" in cfg.model else \"openai\",\r\n",
    "    )\r\n",
    "\r\n",
    "    # 3ï¸âƒ£ æ„é€  LangChain Agentï¼ˆç”¨é€šç”¨ promptï¼‰\r\n",
    "    prompt = hub.pull(\"hwchase17/openai-tools-agent\")\r\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\r\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\r\n",
    "\r\n",
    "    # 4ï¸âƒ£ CLI èŠå¤©\r\n",
    "    print(\"\\nğŸ¤– MCP Agent å·²å¯åŠ¨ï¼Œè¾“å…¥ 'quit' é€€å‡º\")\r\n",
    "    while True:\r\n",
    "        user_input = input(\"\\nä½ : \").strip()\r\n",
    "        if user_input.lower() == \"quit\":\r\n",
    "            break\r\n",
    "        try:\r\n",
    "            result = await agent_executor.ainvoke({\"input\": user_input})\r\n",
    "            print(f\"\\nAI: {result['output']}\")\r\n",
    "        except Exception as exc:\r\n",
    "            print(f\"\\nâš ï¸  å‡ºé”™: {exc}\")\r\n",
    "\r\n",
    "    # 5ï¸âƒ£ æ¸…ç†\r\n",
    "    await mcp_client.cleanup()\r\n",
    "    print(\"ğŸ§¹ èµ„æºå·²æ¸…ç†ï¼ŒBye!\")\r\n",
    "\r\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
    "# å…¥å£\r\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\r\n",
    "    asyncio.run(run_chat_loop())\r\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d3ad9-8e17-4363-a20b-c2f0367f54fe",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`LangChain`æ¥å…¥`MCP`çš„æ ¸å¿ƒåŸç†ä¸ºï¼š `weather_server.py` â†’ å¯åŠ¨ä¸ºå­è¿›ç¨‹ â†’ `stdio` é€šä¿¡ â†’ `MCP` åè®® â†’ è½¬æ¢ä¸º `LangChain` å·¥å…· â†’ `LangChain Agent` æ‰§è¡Œè¯»å†™ï¼Œæ ¸å¿ƒè½¬æ¢è¿‡ç¨‹ä¸ºï¼šï¼š\n",
    "\n",
    "1. `@mcp.tool()` â†’ æ ‡å‡† `LangChain Tool`\n",
    "2. `stdio_client()` â†’ è‡ªåŠ¨å¤„ç† `read/write` æµï¼Œå…¶ä¸­`read` è¡¨ç¤ºä» `MCP` æœåŠ¡å™¨è¯»å–å“åº”çš„æµï¼Œ`write` è¡¨ç¤ºå‘ `MCP` æœåŠ¡å™¨å‘é€è¯·æ±‚çš„æµï¼Œå¯¹äº `stdio weather_server.py`ï¼Œå®ƒä»¬å°±æ˜¯å­è¿›ç¨‹çš„ `stdout` å’Œ `stdin`\n",
    "3. `load_mcp_tools()` â†’ ä¸€é”®è½¬æ¢æ‰€æœ‰å·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a133cf-24b2-4fc0-a987-74595351ff70",
   "metadata": {},
   "source": [
    "å®é™…å¯¹è¯è¿‡ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fedb20-6a38-4a8f-8320-25a9b8f14b9e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171915621.png\" alt=\"image-20250617191543679\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b27c3-950a-4682-a32e-15d9b60f3605",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å®Œæ•´çš„ä»£ç å·²ç»ä¸Šä¼ è‡³ç™¾åº¦ç½‘ç›˜ä¸­çš„`langchain_rag.py`æ–‡ä»¶ä¸­ï¼Œå¤§å®¶å¯ä»¥æ‰«æä¸‹æ–¹äºŒç»´ç å…è´¹é¢†å–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6312f6-97a8-4927-9d46-7b1f4082da24",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506172030599.png\" alt=\"image-20250617203037548\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ce690-8f77-4f45-9e65-8a7a2bd76182",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506102031014.png\" alt=\"6d9391e440ee8df1466cef1bce40705\" style=\"zoom:50%;\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
