{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cfc486c-025e-445f-bc62-6715b33f2ba8",
   "metadata": {},
   "source": [
    "## <font face=\"仿宋\">课程说明："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35fdbe-bc12-421e-8476-ba199dc96972",
   "metadata": {},
   "source": [
    "- 体验课内容节选自[《2025大模型Agent智能体开发实战》(夏季班)](https://ix9mq.xetslk.com/s/3u765N)完整版付费课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd7ea3f-2998-4a53-90db-a9bf3e62c00f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;体验课时间有限，若想深度学习大模型技术，欢迎大家报名由我主讲的[《2025大模型Agent智能体开发实战》(夏季班)](https://ix9mq.xetslk.com/s/3u765N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adec6f-4620-4d62-a85a-67e7d15dd8eb",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/b9ccfe4155bb650c83c4a061f3da131.jpg\" alt=\"d0c81dfe43a1becced8c07db33c3a787_\" style=\"zoom:15%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1769e786-72c6-414f-8a6c-55de081d3a64",
   "metadata": {},
   "source": [
    "**[《2025大模型Agent智能体开发实战》(夏季班)](https://ix9mq.xetslk.com/s/3u765N)为【100+小时】体系大课，总共20大模块精讲精析，零基础直达大模型企业级应用！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44740d9c-8c14-494e-bdc8-102bd850e4bc",
   "metadata": {},
   "source": [
    "<center><img src=\"https://wechatapppro-1252524126.cdn.xiaoeknow.com/appZe9inzwc2314/image/b_u_5ea8e780054d6_Fop5bmXf/6aueuzm7qbtmje.png?imageView2/2/q/80|imageMogr2/ignore-error/1\" alt=\"img\" style=\"zoom: 33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e7ca0-85c1-4899-8906-968028b074b2",
   "metadata": {},
   "source": [
    "部分项目成果演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb571498-aabf-4041-ab67-da203e747af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86dba4c-cce1-448c-bfc4-de6b1966f037",
   "metadata": {},
   "source": [
    "- **MateGen项目演示**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a5f3b1-6032-453e-86bc-bf81f5d49380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/4.MateGen%20Pro%20%E9%A1%B9%E7%9B%AE%E5%8A%9F%E8%83%BD%E6%BC%94%E7%A4%BA.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/4.MateGen%20Pro%20%E9%A1%B9%E7%9B%AE%E5%8A%9F%E8%83%BD%E6%BC%94%E7%A4%BA.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d00164-82d8-45d0-8ede-d7e48c04e2a5",
   "metadata": {},
   "source": [
    "- **智能客服项目演示**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea896d78-8e6a-44d7-a1a6-762053441a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7441c1f1-96d1-43a5-bc0d-d52cc23230e4",
   "metadata": {},
   "source": [
    "- **Dify项目演示**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581ec1b9-51c3-426e-a5b6-dca7c46ecfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/2f1b47f42c65fd59e8d3a83e6cb9f13b_raw.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/2f1b47f42c65fd59e8d3a83e6cb9f13b_raw.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17a819-2c12-456c-98d4-25289227350a",
   "metadata": {},
   "source": [
    "- **LangChain&LangGraph搭建Multi-Agnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2719d2c-2808-4f52-be2d-93b78e417165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90Multi-Agent%E6%95%88%E6%9E%9C%E6%BC%94%E7%A4%BA%E6%95%88%E6%9E%9C.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90Multi-Agent%E6%95%88%E6%9E%9C%E6%BC%94%E7%A4%BA%E6%95%88%E6%9E%9C.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c161bcb-8e24-4005-a403-7007b21c40ba",
   "metadata": {},
   "source": [
    "此外，若是对大模型底层原理感兴趣，也欢迎报名由我和菜菜老师共同主讲的[《2025大模型原理与实战课程》(夏季班)](https://ix9mq.xetslk.com/s/49L2eN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b75fa9-68fa-49bf-85eb-0e496b5711b0",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/da5d51c998df07d747cd223c1ed25f7.jpg\" alt=\"da5d51c998df07d747cd223c1ed25f7\" style=\"zoom:20%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e820561-fa6e-4bd5-8280-d22cadc9219a",
   "metadata": {},
   "source": [
    "**两门大模型课程夏季班目前上新特惠+618年中钜惠双惠叠加，合购还有更多优惠哦~<span style=\"color:red;\">详细信息扫码添加助教，回复“大模型”，即可领取课程大纲&查看课程详情👇</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575820a-1038-4691-bc56-7a8d6922e06e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506101749045.png\" alt=\"6d9391e440ee8df1466cef1bce40705\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301dfb6-b8c2-4362-b20f-11eb4d41ad5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaeeead-445e-4361-88e0-beb79d50344e",
   "metadata": {},
   "source": [
    "# <center> LangChain快速入门与Agent开发实战\n",
    "# <center> Part 2.各类模型接入LangChain流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9533e48-4890-4126-9f13-f148191222fd",
   "metadata": {},
   "source": [
    "- LangChain项目回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320ea65-0b11-4327-b22d-cd40876c9fbe",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`LangChain`可以称之为自`2022年底`大模型技术爆火以来的第一个真正意义上的大模型开发框架。\n",
    "\n",
    "&emsp;&emsp;大模型本质上无法直接解决实际的问题，仅仅是一个能够分析、推理和生成文本的黑盒。直到现在，所有的开发者们仍然在不断探索如何把大模型的强大能力与实际应用场景结合起来，而当时`LangChain`的出现，直接让大模型开发变得简单起来，它将大模型开发过程中常用的功能、工具、流程等等全部封装成一个个的组件，使开发者可以像搭乐高积木一样，快速的组合出适用于不同场景需求的大模型应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec0aef-9ed4-4ba9-971c-f77764e1047a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`LangChain`的首个版本于`2022年10月`开源，直到现在仍然再以一个飞快的速度不断进行迭代升级。从一个开源 `Python/TS` 框架逐渐发展，形成包括“链”和“代理”等核心组件，现在已走向企业级阶段，发展成了`LangChain AI`，其拥有目前`Agent`技术领域最大的开源生态，衍生出了多个开源项目框架，各自都在大模型的技术领域承担着不同的开发任务角色。 \n",
    "\n",
    "&emsp;&emsp;其官方`Github`地址为：https://github.com/langchain-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558fff9-70c1-4b4c-b846-349a01951c39",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202506091051864.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb606f3-43ff-46e2-a2d5-4235e591af55",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们可以梳理出在`LangChain AI`中最受关注的项目发展态势，如下图所示：\n",
    "\n",
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202506091051866.png\" width=45%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e333de4-fa1d-4c02-8191-113f24275ee0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其中最活跃的项目当属`langchain`，排在前二的分别是`langChain`的`Python`版本和`JavaScript`版本。作为`LangChain AI`发展的基石，`langchain`主要用来支持构建大模型应用的一切，包括链式编排、检索增强生成 (RAG)、嵌入、文档处理、对话系统、代码分析等。而随着业务需求的越来越复杂，`LangChain AI`也推出了`langgraph`，作为一个基于图结构的 `Agent` 编排框架，可构建有状态、多步骤、多 `Agent` 的工作流，从而进一步扩展了`LangChain AI`自家生态的适用范围。而至于`local‑deep‑researcher`和`opengpts`，则完全是给开发者提供了基于`LangChain`定制开发出的特定热门应用，也一定程度上能印证`LangChain AI`的生态繁荣和可实现应用场景的广度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d26a3c-d8b4-4430-a06f-d8a1dd63263d",
   "metadata": {},
   "source": [
    "- LangChain AI 热门开源项目功能介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291767a-a2e5-4f5d-a8ef-b56c4ee17c02",
   "metadata": {},
   "source": [
    "\n",
    "| 项目                        | 技术栈              | 核心用途                          |\n",
    "| ------------------------- | ---------------- | ----------------------------- |\n",
    "| **langchain**             | Python/TS        | 构建 LLM 应用基础组件                 |\n",
    "| **langchainjs**           | JS/TS            | 前端/Node 环境中构造 LLM 应用          |\n",
    "| **langgraph**             | Python           | 用图编排复杂 agent 流程               |\n",
    "| **local‑deep‑researcher** | Python           | 自动化、多轮本地 Web 研究工具             |\n",
    "| **opengpts**              | Python + Go + 前端 | 可定制化 GPT 平台，支持 RAG 和 agent 开发 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02ff16-a648-4afc-bf29-d01616d34ca1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对外，`LangChain` 也是目前大模型技术领域所有`AI Agent`框架中最热门、最通用的，相较于`AutoGen`、`CrewAI`、`OpenAI Agents SDK`和`Google ADK`，拥有最多的收藏量和活跃的开发者数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2a4d0-9b32-4c6b-967c-68c01ed45e7a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/image-20250609220554934.png\" width=45%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826ea56-0ee3-41be-8f5b-3c90e391726f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;因此这里大家可以感受到，`langChain AI`生态的学习，其实最最核心的就是`LangChain`这个项目。而`langChain`是一个非常全面的开发框架，集成了`Agent`和`RAG`两个关键的热门落地方向，通过灵活的模块化组合可以快速的构建适用于私有业务场景的大模型应用，在目前的应用开发中是企业中使用最多的`Agent`开发框架。其核心架构如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5ee32-9fa9-46c8-85f2-94a5ff3f49b4",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/langchain_arch.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4365d7-8cc6-4408-937c-5a7e11507e55",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从本质上分析，`LangChain`从大模型角度出发，通过开发人员在实践过程中对大模型能力的深入理解及其在不同场景下的涌现潜力，使用模块化的方式进行高级抽象，设计出统一接口以适配各种大模型。`LangChain`抽象出最重要的核心模块如下：\n",
    "\n",
    "1. `Model I/O` ：标准化各个大模型的输入和输出，包含输入模版，模型本身和格式化输出；\n",
    "2. `Retrieval` ：检索外部数据，然后在执行生成步骤时将其传递到 LLM，包括文档加载、切割、Embedding等；\n",
    "3. `Chains` ：链，`LangChain`框架中最重要的模块，链接多个模块协同构建应用，是实际运作很多功能的高级抽象；\n",
    "4. `Memory` ： 记忆模块，以各种方式构建历史信息，维护有关实体及其关系的信息；\n",
    "5. `Agents` ： 目前最热门的`Agents`开发实践，未来能够真正实现通用人工智能的落地方案；\n",
    "6. `Callbacks` ：回调系统，允许连接到 大模型 应用程序的各个阶段。用于日志记录、监控、流传输和其他任务；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ec6ad-6c53-4eee-8cae-a4520ca39b56",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从上图中可以看到，`LangChain`框架涵盖了模型输入输出的标准化、外部工具接入的规范、上下文记忆功能，以及对数据库、SQL、CSV等多种数据源的连接标准。通过核心的\"Chain\"高级抽象，定义了不同形式下标准的链接方法，这就能够允许开发者根据实际的应用需求和数据流向快速构建出一套完整的应用程序。这个过程类似于搭建积木，可以灵活适应不同的任务需求。\n",
    "\n",
    "&emsp;&emsp;因此本节公开课，我们就围绕`LangChain`展开详细的讲解，我们会涉及到`LangChain`框架的整体概览，如何用`LangChain`搭建智能体和本地知识库问答的完整流程，同时对于比较热门的`MCP`工具如何接入`LangChain`框架，会做一个重点的说明。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4d881-1a66-443c-82db-45b9d61b3968",
   "metadata": {},
   "source": [
    "&emsp;&emsp;需要说明的，这里我们选择使用`Python`作为开发语言，同时使用目前最新的`LangChain 0.3`版本，具体的版本说明如下：\n",
    "\n",
    "- Python==3.12\n",
    "- LangChain>=0.3.25\n",
    "- langchain-deepseek>=0.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47db78-fe16-495a-b930-d1808723b237",
   "metadata": {},
   "source": [
    "### 1. LangChain接入大模型流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f78405-fd62-4f27-b357-6427e23d6562",
   "metadata": {},
   "source": [
    "- LangChain安装流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73828e-667d-49fb-be18-f85266bb46bc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果使用`LangChain`进行大模型应用开发，需要安装`LangChain`的依赖包，安装命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c53f1ca-b231-4392-b4b6-dbf115e8cdd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Using cached langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.2.3-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached greenlet-3.2.3-cp312-cp312-win_amd64.whl (297 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tenacity, sniffio, PyYAML, packaging, orjson, jsonpointer, idna, h11, greenlet, charset-normalizer, certifi, annotated-types, typing-inspection, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\n",
      "   ---- -----------------------------------  3/29 [tenacity]\n",
      "  Attempting uninstall: packaging\n",
      "   ---- -----------------------------------  3/29 [tenacity]\n",
      "    Found existing installation: packaging 25.0\n",
      "   ---- -----------------------------------  3/29 [tenacity]\n",
      "    Uninstalling packaging-25.0:\n",
      "   ---- -----------------------------------  3/29 [tenacity]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   ---- -----------------------------------  3/29 [tenacity]\n",
      "   ------------ ---------------------------  9/29 [idna]\n",
      "   --------------- ------------------------ 11/29 [greenlet]\n",
      "   ---------------------- ----------------- 16/29 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 16/29 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 16/29 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 16/29 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 16/29 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 16/29 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 16/29 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 17/29 [requests]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ------------------------------- -------- 23/29 [pydantic]\n",
      "   ------------------------------- -------- 23/29 [pydantic]\n",
      "   ------------------------------- -------- 23/29 [pydantic]\n",
      "   ---------------------------------- ----- 25/29 [langsmith]\n",
      "   ---------------------------------- ----- 25/29 [langsmith]\n",
      "   ----------------------------------- ---- 26/29 [langchain-core]\n",
      "   ----------------------------------- ---- 26/29 [langchain-core]\n",
      "   ------------------------------------- -- 27/29 [langchain-text-splitters]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   -------------------------------------- - 28/29 [langchain]\n",
      "   ---------------------------------------- 29/29 [langchain]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.41 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.4.26 charset-normalizer-3.4.2 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-core-0.3.64 langchain-text-splitters-0.3.8 langsmith-0.3.45 orjson-3.10.18 packaging-24.2 pydantic-2.11.5 pydantic-core-2.33.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.14.0 typing-inspection-0.4.1 urllib3-2.4.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e0634-ae64-44e6-aea7-aa36a6ac5acb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不同的依赖包版本在使用方式上可能存在一些差异，所以建议大家选择和课程一直的依赖包版本进行学习。这里我们采用的是目前最新的`LangChain 0.3`版本，可以通过如下命令进行查看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718ada4d-461a-40ca-b743-8e8626af66a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.25\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /root/anaconda3/lib/python3.12/site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community, open-webui\n"
     ]
    }
   ],
   "source": [
    "! pip show langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbef29-2c02-4eef-b59b-8d13c2238bcc",
   "metadata": {},
   "source": [
    "- 尝试调用DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cc2de-6ffc-48f1-acc8-c72226ebaac2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在进行`LangChain`开发之前，首先需要准备一个可以进行调用的大模型，这里我们选择使用`DeepSeek`的大模型，并使用`DeepSeek`官方的`API_KEK`进行调用。如果初次使用，需要现在`DeepSeek`官网上进行注册并创建一个新的`API_Key`，其官方地址为：https://platform.deepseek.com/usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337c44c-8e37-4480-b585-a806c9bdf075",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202506091257041.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc859cf6-8817-4801-b2d4-eea04c8b2b1a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;注册好`DeepSeek`的`API_KEY`后，首先在项目同级目录下创建一个`env`文件，用于存储`DeepSeek`的`API_KEY`，如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2da03-5570-45fc-95b8-80691eef981b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506101758896.png\" alt=\"image-20250610175750011\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfeb0ec-7bd6-471e-b024-43e554e70d41",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506101759417.png\" alt=\"image-20250610175921388\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccc22c-c8da-462d-8546-ac74aea1c8b6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来通过`python-dotenv`库读取`env`文件中的`API_KEY`，使其加载到当前的运行环境中，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8df71a-09f1-4d0a-be40-e6f05db0f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /root/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d99073-1c36-41aa-b8a0-e7263f97af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv(override=True)\n",
    "\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# print(DeepSeek_API_KEY)  # 可以通过打印查看"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffce0e5-27a3-4fd7-a74e-14d15cd620bc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们在当前的运行环境下不使用`LangChain`，直接使用`DeepSeek`的`API`进行网络连通性测试，测试代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be03fedc-0abd-44bb-bcd9-3360337d5626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /root/anaconda3/lib/python3.12/site-packages (1.78.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /root/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /root/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/anaconda3/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902ca1e2-514a-4b81-bcf8-c97d7f288617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个乐于助人的AI助手，随时准备为你提供帮助。我可以回答各种问题、提供建议、协助解决问题，或者陪你聊天。无论是学习、工作还是日常生活，我都会尽力为你提供有用的信息和支持。 \n",
      "\n",
      "我的知识涵盖了多个领域，包括但不限于科技、历史、文化、健康、编程等。如果你有任何疑问或需要帮助，随时告诉我！ 😊 \n",
      "\n",
      "你想了解关于我的具体方面，还是需要其他帮助呢？\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 初始化DeepSeek的API客户端\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# 调用DeepSeek的API，生成回答\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是乐于助人的助手，请根据用户的问题给出回答\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，请你介绍一下你自己。\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 打印模型最终的响应结果\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05665596-d01e-40df-9a16-1e8e187bc469",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果可以正常收到`DeepSeek`模型的响应，则说明`DeepSeek`的`API`已经可以正常使用且网络连通性正常。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4c53d-6b56-42f0-b6fe-c178018a78aa",
   "metadata": {},
   "source": [
    "- DeepSeek接入LangChain流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9498851-1df6-47de-b995-bcdd6ae86816",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们要考虑的是，对于这样一个`DeepSeek`官方的`API`，如何接入到`LangChain`中呢？其实非常简单，我们只需要使用`LangChain`中的一个`DeepSeek`组件即可向像述代码一样，直接使用相同的`DeepSeek API KEY`与大模型进行交互。因此，我们首先需要安装`LangChain`的`DeepSeek`组件，安装命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d82e4c-9805-420c-bcb6-4cee6cac5553",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-deepseek\n",
      "  Downloading langchain_deepseek-0.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in /root/anaconda3/lib/python3.12/site-packages (from langchain-deepseek) (0.3.64)\n",
      "Collecting langchain-openai<1.0.0,>=0.3.9 (from langchain-deepseek)\n",
      "  Downloading langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.11.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /root/anaconda3/lib/python3.12/site-packages (from langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (1.78.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /root/anaconda3/lib/python3.12/site-packages (from langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (0.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (3.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/anaconda3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (2023.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in /root/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (3.7)\n",
      "Requirement already satisfied: certifi in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.2.2)\n",
      "Downloading langchain_deepseek-0.1.3-py3-none-any.whl (7.1 kB)\n",
      "Downloading langchain_openai-0.3.21-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m4.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-openai, langchain-deepseek\n",
      "Successfully installed langchain-deepseek-0.1.3 langchain-openai-0.3.21\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install langchain-deepseek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac304981-5fcf-4510-9bcf-4e1476bceb06",
   "metadata": {},
   "source": [
    "&emsp;&emsp;安装好`LangChain`集成`DeepSeek`模型的依赖包后，需要通过一个`init_chat_model`函数来初始化大模型，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d22ef4a-3e43-42cf-9b90-5d13c61fd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338af96-18bc-4d3f-b957-d1d76f19f9e1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其中`model`用来指定要使用的模型名称，而`model_provider`用来指定模型提供者，当写入`deepseek`时，会自动加载`langchain-deepseek`的依赖包，并使用在`model`中指定的模型名称用来进行交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cef5533-67ce-4c3f-967f-615a8673d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是 **DeepSeek Chat**，由深度求索公司（DeepSeek）研发的一款智能AI助手。我可以帮助你解答各种问题，包括学习、工作、编程、写作、生活百科等多个领域。  \n",
      "\n",
      "### **我的特点：**  \n",
      "✅ **免费使用**：目前无需付费，你可以随时向我提问！  \n",
      "✅ **知识丰富**：我的知识截止到 **2024年7月**，可以为你提供较新的信息。  \n",
      "✅ **超长上下文支持**：可以处理 **128K** 长度的文本，适合分析长文档或复杂问题。  \n",
      "✅ **文件阅读**：支持上传 **PDF、Word、Excel、PPT、TXT** 等文件，并从中提取信息进行分析。  \n",
      "✅ **多语言能力**：可以用中文、英文等多种语言交流，帮助你翻译或学习外语。  \n",
      "✅ **编程助手**：能写代码、调试、优化算法，支持Python、C++、Java等多种编程语言。  \n",
      "\n",
      "### **我能帮你做什么？**  \n",
      "📖 **学习辅导**：解题思路、论文写作、知识点讲解  \n",
      "💼 **工作效率**：写邮件、做PPT、总结报告  \n",
      "💡 **创意灵感**：写故事、起名字、头脑风暴  \n",
      "📊 **数据分析**：处理表格、绘制图表、解读数据  \n",
      "🔧 **技术支持**：代码调试、算法优化、技术咨询  \n",
      "\n",
      "你可以随时向我提问，我会尽力提供最准确、有用的回答！😊 有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "source": [
    "question = \"你好，请你介绍一下你自己。\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c64765-a835-4250-85cd-e86ef879b5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！我是 **DeepSeek Chat**，由深度求索公司（DeepSeek）研发的一款智能AI助手。我可以帮助你解答各种问题，包括学习、工作、编程、写作、生活百科等多个领域。  \\n\\n### **我的特点：**  \\n✅ **免费使用**：目前无需付费，你可以随时向我提问！  \\n✅ **知识丰富**：我的知识截止到 **2024年7月**，可以为你提供较新的信息。  \\n✅ **超长上下文支持**：可以处理 **128K** 长度的文本，适合分析长文档或复杂问题。  \\n✅ **文件阅读**：支持上传 **PDF、Word、Excel、PPT、TXT** 等文件，并从中提取信息进行分析。  \\n✅ **多语言能力**：可以用中文、英文等多种语言交流，帮助你翻译或学习外语。  \\n✅ **编程助手**：能写代码、调试、优化算法，支持Python、C++、Java等多种编程语言。  \\n\\n### **我能帮你做什么？**  \\n📖 **学习辅导**：解题思路、论文写作、知识点讲解  \\n💼 **工作效率**：写邮件、做PPT、总结报告  \\n💡 **创意灵感**：写故事、起名字、头脑风暴  \\n📊 **数据分析**：处理表格、绘制图表、解读数据  \\n🔧 **技术支持**：代码调试、算法优化、技术咨询  \\n\\n你可以随时向我提问，我会尽力提供最准确、有用的回答！😊 有什么我可以帮你的吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 9, 'total_tokens': 320, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 9}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': 'e3323dc0-46fa-497b-aaf5-83596184f8b2', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--9f652093-6feb-484f-99f7-0c30e33290ab-0', usage_metadata={'input_tokens': 9, 'output_tokens': 311, 'total_tokens': 320, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b10b118-eb20-4949-b0d0-535748a3e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好呀！👋我是 **DeepSeek-R1**，由中国的人工智能公司「深度求索」研发。你可以把我当作一个聪明、热心、24小时在线的文字助手～✨\n",
      "\n",
      "---\n",
      "\n",
      "### 🌟 我的特点：\n",
      "- **知识丰富**：截至2024年7月前的各种知识我都有所了解，无论是学习、工作、生活，还是科技、历史、娱乐，我都能帮上忙。\n",
      "- **超长记忆力**：可以处理长达128K上下文的内容，也就是说，你发给我超长的文件或对话，我也能理解清楚！\n",
      "- **文件助手**：支持你上传 **PDF、Word、PPT、Excel、图片** 等文件，我能帮你阅读、总结、提取重点。\n",
      "- **免费使用**（目前是哦！🎉）而且**无需登录**也能畅快聊天（不过登录后能保存历史记录更方便～）\n",
      "\n",
      "---\n",
      "\n",
      "### 🛠 我能做什么？\n",
      "✅ 解答问题（学习、考试、百科）  \n",
      "✅ 写作助手（作文、小说、文案、邮件）  \n",
      "✅ 编程帮手（写代码、查bug、讲算法）  \n",
      "✅ 文件处理（读论文、总结报告、提取数据）  \n",
      "✅ 生活助手（旅游攻略、美食推荐、情感建议）\n",
      "\n",
      "---\n",
      "\n",
      "### 🧠 我的“小限制”：\n",
      "- 目前是**纯文字模型**，不支持语音或识图（但你可以上传图片文件，我能读取里面的文字）。\n",
      "- 我的知识截止在 **2024年7月**，之后的新事件就不太清楚啦。\n",
      "- 我不是真人，但我会尽力用温暖、贴心的方式和你交流 ❤️\n",
      "\n",
      "---\n",
      "\n",
      "不管你是学生、上班族、创作者，还是只是好奇想聊聊天——我都在这儿等你！😊  \n",
      "现在，有什么我可以帮你的吗？比如学习上的难题、工作中的任务，或者生活里的小烦恼？\n"
     ]
    }
   ],
   "source": [
    "model = init_chat_model(model=\"deepseek-reasoner\", model_provider=\"deepseek\")  \n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a6966f-a388-496d-b4f2-67efb94f1b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'refusal': None,\n",
       " 'reasoning_content': '嗯，用户发来一句简单的问候和自我介绍请求。看起来像是初次接触的破冰场景，可能刚打开聊天界面或者第一次使用这类AI助手。\\n\\n用户语气礼貌但比较笼统，没有具体需求指向。这种开放式问题通常有两种可能：一是真的想了解AI的功能边界，二是测试性提问看AI如何反应。考虑到中文互联网环境里常有用户用“介绍自己”测试机器人，需要同时做好信息传递和破冰互动。\\n\\n回复策略上应该突出三点：明确身份属性（非人类但能做什么）、消除陌生感（用表情符号和分段提升可读性）、引导后续对话（结尾提问）。要避免机械的术语堆砌，比如不说“基于Transformer架构”而说“能帮你查资料”。\\n\\n用户没透露任何个人信息，就用中性称呼。最后那个🎉表情可能有点过，不过新用户首次互动需要点活泼感——要是商务场景用户应该会直接问专业问题吧。结尾提问选“学习/工作/生活”三个维度覆盖常见场景，比单问“有什么可以帮你”更易触发具体需求。'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bea0f51-7a77-497c-a838-30fdf491d2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'嗯，用户发来一句简单的问候和自我介绍请求。看起来像是初次接触的破冰场景，可能刚打开聊天界面或者第一次使用这类AI助手。\\n\\n用户语气礼貌但比较笼统，没有具体需求指向。这种开放式问题通常有两种可能：一是真的想了解AI的功能边界，二是测试性提问看AI如何反应。考虑到中文互联网环境里常有用户用“介绍自己”测试机器人，需要同时做好信息传递和破冰互动。\\n\\n回复策略上应该突出三点：明确身份属性（非人类但能做什么）、消除陌生感（用表情符号和分段提升可读性）、引导后续对话（结尾提问）。要避免机械的术语堆砌，比如不说“基于Transformer架构”而说“能帮你查资料”。\\n\\n用户没透露任何个人信息，就用中性称呼。最后那个🎉表情可能有点过，不过新用户首次互动需要点活泼感——要是商务场景用户应该会直接问专业问题吧。结尾提问选“学习/工作/生活”三个维度覆盖常见场景，比单问“有什么可以帮你”更易触发具体需求。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.additional_kwargs['reasoning_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7dcc4a-32bb-4814-adf1-b05ba349301a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里可以看到，仅仅通过两行代码，我们便可以在`LangChain`中顺利调用`DeepSeek`模型，并得到模型的响应结果。相较于使用`DeepSeek`的`API`，使用`LangChain`调用模型无疑是更加简单的。同时，不仅仅是`DeepSeek`模型，`LangChain`还支持其他很多大模型，如`OpenAI`、`Qwen`、`Gemini`等，我们只需要在`init_chat_model`函数中指定不同的模型名称，就可以调用不同的模型。其工作的原理是这样的："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f3e08-617f-4fb7-8534-2bec30c6414f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202506091353369.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90689bdb-1f8f-4255-9ed2-80cd471c21d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;理解了这个基本原理，如果大家想在用`LangChain`进行开发时使用其他大模型如`Qwen3`系列，则只需要先获取到`Qwen3`模型的`API_KEY`，然后安装`Tongyi Qwen`的第三方依赖包，即可同样通过`init_chat_model`函数来初始化模型，并调用`invoke`方法来得到模型的响应结果。关于`LangChain`都支持哪些大模型以及每个模型对应的是哪个第三方依赖包，大家可以在`LangChain`的官方文档中找到，访问链接为：https://python.langchain.com/docs/integrations/chat/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93617d-56c9-462f-abda-b59f691b3fa0",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202506091359607.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4abf6-46f0-4a52-ab36-cbc3fe452512",
   "metadata": {},
   "source": [
    "- 【补充】LangChain接入OpenAI模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c5d976-f505-47f6-8413-f3fe28d7dc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /root/anaconda3/lib/python3.12/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.64 in /root/anaconda3/lib/python3.12/site-packages (from langchain-openai) (0.3.64)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /root/anaconda3/lib/python3.12/site-packages (from langchain-openai) (1.78.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /root/anaconda3/lib/python3.12/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.11.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /root/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/anaconda3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /root/anaconda3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /root/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669b18cc-62c9-404e-9db4-d510836406e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个人工智能助手，旨在帮助用户解答问题、提供信息和支持。我可以处理各种主题的询问，比如科技、历史、文化、语言学习等。如果你有任何问题或需要帮助的地方，请随时问我！\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "question = \"你好，请你介绍一下你自己。\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce342b6b-511a-48c9-9c2b-423d5665fc2e",
   "metadata": {},
   "source": [
    "> 注1：使用OpenAI模型前需要设置好网络环境。             \n",
    "> 注2：更多OpenAI、Claude、Gemini模型接入指南，详见赋范大模型技术社区文档：\n",
    "> <center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121657437.png\" alt=\"image-20250612165757386\" style=\"zoom:33%;\" />      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dafab1-5acd-47e0-a5a8-c22ed33db26c",
   "metadata": {},
   "source": [
    "> <center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121701348.png\" alt=\"57d34aa34ec04a98b020018c55b242d\" style=\"zoom:23%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2cc5d-deca-4a7e-8ea2-9090e797b6ea",
   "metadata": {},
   "source": [
    "- 【补充】接入Dashscope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f19120-3516-48d1-a20e-903e7c35cd3e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Dashscope原名是阿里云的灵积社区，也是国内最大的API集成平台，其中包含了各类开源模型（如Qwen3系列模型）和国内在线模型（如DeepSeek、BaiChuan）模型API服务，现在已合并入阿里云百炼平台。对于国内开发者来说，若要使用Qwen系列模型API（而非本地部署），那么Dashscope平台提供的API服务肯定是最合适的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e2718-f9e3-427c-85ef-8e1f3a35b7ee",
   "metadata": {},
   "source": [
    "阿里百炼平台官网：https://bailian.console.aliyun.com/?switchAgent=11366636&productCode=p_efm&switchUserType=3&tab=home#/home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d4a9c-895b-48e9-9427-b1071b8ef326",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121643946.png\" alt=\"image-20250612164327753\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8fb7bc-ac0f-41b3-bd52-9ab6919f238a",
   "metadata": {},
   "source": [
    "而百炼API获取方式也非常简单，只需注册阿里云账号，然后前往我的API页面：https://bailian.console.aliyun.com/?tab=model#/api-key 进行充值和注册即可："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45db8fd-9f34-4173-b8c3-314036ca3817",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121644323.png\" alt=\"image-20250612164439194\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a611c-90ad-4c20-ab2b-ca34a21307ac",
   "metadata": {},
   "source": [
    "然后即可调用海量各类模型了："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29caae0-6655-4071-ba8d-caa5b8b96168",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121645006.png\" alt=\"image-20250612164516862\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c2a4b-3135-4fce-ae00-b64f050eb90f",
   "metadata": {},
   "source": [
    "当我们完成了DashScope API注册后，即可使用如下代码进行模型调用（需要提前将DASHSCOPE_API_KEY写到本地.env文件中）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af11c30c-5199-4b25-804f-a28b153dee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-17b9c16c-1380-9843-898a-b2fd91e40d80\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我能够回答问题、创作文字，如写故事、公文、邮件、剧本等，还能进行逻辑推理、编程，甚至表达观点和玩游戏。我在多国语言上都有很好的掌握，能为你提供多样化的帮助。有什么我可以帮到你的吗？\",\"refusal\":null,\"role\":\"assistant\",\"annotations\":null,\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1749718136,\"model\":\"qwen-plus\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":75,\"prompt_tokens\":22,\"total_tokens\":97,\"completion_tokens_details\":null,\"prompt_tokens_details\":{\"audio_tokens\":null,\"cached_tokens\":0}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁？\"},\n",
    "    ],\n",
    ")\n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f66ff9-e559-4876-bc79-30486c3271ce",
   "metadata": {},
   "source": [
    "当然，也可以将DashScope中各类模型接入LangChain："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3323ae7-107a-4146-b62a-b837b8a8d6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting dashscope\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5a/6e/b5c2d35ed026bbe6d9e06d069667e5b6c20df6933bcf13f8b352cb8a89de/dashscope-1.23.4-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /root/anaconda3/lib/python3.12/site-packages (from dashscope) (3.11.18)\n",
      "Requirement already satisfied: requests in /root/anaconda3/lib/python3.12/site-packages (from dashscope) (2.32.3)\n",
      "Requirement already satisfied: websocket-client in /root/anaconda3/lib/python3.12/site-packages (from dashscope) (1.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/anaconda3/lib/python3.12/site-packages (from aiohttp->dashscope) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/lib/python3.12/site-packages (from requests->dashscope) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/lib/python3.12/site-packages (from requests->dashscope) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/lib/python3.12/site-packages (from requests->dashscope) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.12/site-packages (from requests->dashscope) (2024.2.2)\n",
      "Installing collected packages: dashscope\n",
      "Successfully installed dashscope-1.23.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade dashscope -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187b3fad-eff7-4401-8a0b-c80c6af9bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff96fff-5486-40af-b892-eb2cb791b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatTongyi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52aeba71-175b-43e9-98e5-089188565a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是通义千问，阿里巴巴集团旗下的超大规模语言模型。我能够帮助你完成各种任务，提供有用的信息和建议。无论是写故事、公文、技术文档，还是表达观点、玩游戏等，我都可以尽力协助。如果你有任何问题或需要帮助，尽管告诉我，我会尽最大努力满足你的需求。😊\n"
     ]
    }
   ],
   "source": [
    "question = \"你好，请你介绍一下你自己。\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379a9cf-512f-4362-92e9-be334b0d1200",
   "metadata": {},
   "source": [
    "- 【补充】ollama开源大模型接入LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502880e-e53f-4524-85f7-0657c847a79b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，除了在线大模型的接入，`langChain`也只是使用`Ollama`、`vLLM`等框架启动的本地大模型。这里以ollama为例进行演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cbc3895-0267-4242-8157-8d5f63f794ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.3.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting ollama<1.0.0,>=0.4.8 (from langchain-ollama)\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.60 in /root/anaconda3/lib/python3.12/site-packages (from langchain-ollama) (0.3.64)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /root/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.11.4)\n",
      "Requirement already satisfied: httpx>=0.27 in /root/anaconda3/lib/python3.12/site-packages (from ollama<1.0.0,>=0.4.8->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in /root/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /root/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /root/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /root/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.3.0)\n",
      "Downloading langchain_ollama-0.3.3-py3-none-any.whl (21 kB)\n",
      "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain-ollama\n",
      "Successfully installed langchain-ollama-0.3.3 ollama-0.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a446d2a7-663f-4e95-bef0-a00f7fc0b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87de8e4-dfa4-45a6-ab96-503cb44fd98d",
   "metadata": {},
   "source": [
    "注意，这里要确保ollama已经顺利开启，并查看当前模型名称："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75838abc-2053-4e2a-a01a-0e740732f8c9",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121701138.png\" alt=\"image-20250612170158115\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e516467e-4f31-41d1-8472-144024fa14c3",
   "metadata": {},
   "source": [
    "然后即可使用如下方法接入LangChain："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94e004fc-e28e-44b5-812a-0712c9b838fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"deepseek-r1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1421f7-1c64-4729-8039-5d0e3fb633fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，用户发来一个简单的问候和自我介绍请求。这可能是第一次接触我，或者想确认我的功能范围。\n",
      "\n",
      "用户可能刚打开聊天界面，带着一点好奇和试探的心理。ta不一定有明确需求，更像是在“暖场”，测试这个AI助手能做什么。这类开场白很常见，需要既保持友好又清晰展示能力边界。\n",
      "\n",
      "考虑到这是基础社交场景，回复应该包含几个关键要素：身份说明（DeepSeek-R1）、开发者信息（增加可信度）、核心功能范围（让用户快速建立认知）、交互邀请（降低使用门槛）。语气要轻快但专业，用emoji调节严肃感，避免术语堆砌。\n",
      "\n",
      "用户没透露任何背景信息，所以保持中性称呼最稳妥。最后那个“😊”表情很重要——既承接了开头的问候情绪，又暗示AI助手具备情感交互能力，比纯文字更亲切。\n",
      "</think>\n",
      "你好呀！👋我是DeepSeek-R1，一个由深度求索公司开发的人工智能助手，可以帮助你处理各种文本任务、回答问题、提供知识信息和进行创意创作。我的知识更新到2024年7月，涵盖科学、历史、文学、技术等多个领域，并且支持中文和英文交流。\n",
      "\n",
      "我可以帮你做很多事，比如：\n",
      "\n",
      "- 解答学习或工作上的疑问\n",
      "- 编辑润色文案写作（论文、邮件、报告都可以）\n",
      "- 总结整理复杂信息\n",
      "- 进行多轮对话讨论某一主题\n",
      "- 提供编程帮助（代码解释、调试、生成等）\n",
      "- 甚至帮你规划旅行，推荐书籍电影，写诗写情书 😄\n",
      "\n",
      "如果你有任何问题或需要帮忙的地方，尽管告诉我吧！我随时在线，乐意为你服务～😊\n"
     ]
    }
   ],
   "source": [
    "question = \"你好，请你介绍一下你自己。\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1025fc8-8d75-437b-88ad-e98217bb3d1a",
   "metadata": {},
   "source": [
    "> 注：更多ollama、vLLM使用方法，及Qwen3、DeepSeek系列模型本地部署流程，详见赋范大模型技术社区教程：             \n",
    "> <center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121700560.png\" alt=\"image-20250612170044518\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b3c206-edd8-4f29-a4ff-ed11bce9f569",
   "metadata": {},
   "source": [
    "> <center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506121701348.png\" alt=\"57d34aa34ec04a98b020018c55b242d\" style=\"zoom:23%;\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
